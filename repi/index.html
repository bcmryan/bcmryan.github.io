<!DOCTYPE html>
<html lang="en_US">
  <head>
  	<meta charset="utf-8">
  	<meta name="viewport"    content="width=device-width, initial-scale=1.0">
  	<meta name="description" content="">
  	<meta name="author"      content="map[]">
    
    	<title>RePi</title>
	<link rel="shortcut icon" href="/images/favicon.icon">

	
	<link href="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.no-icons.min.css" rel="stylesheet">
	
	
	<script defer src="https://use.fontawesome.com/releases/v5.0.11/js/all.js" integrity="sha384-ImVoB8Er8knetgQakxuBS4G3RSkyD8IZVVQCAnmRJrDwqJFYUE4YOv+DbIofcO9C" crossorigin="anonymous"></script>
	
	
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Alice|Open+Sans:400,300,700">
	
	
  
  <link rel="stylesheet" href="/css/styles.min.64a6643395c6bf1ec6fff31d6429046b3ad467e58a279ff252dc019edd80a87051cf90b7fe2d589277def72d84602dcbc7115e2e17a94db3a8838336986a0ae3.css" integrity="sha512-ZKZkM5XGvx7G//MdZCkEazrUZ&#43;WKJ5/yUtwBnt2AqHBRz5C3/i1Yknfe9y2EYC3LxxFeLhepTbOog4M2mGoK4w==">

   
  

  </head>
  
  <body class="home">

    
      <header id="header">
  <div id="head" class="parallax" data-parallax-speed="2" style="background-image:url('/images/bg_head.png');">
    <h1 id="logo" class="text-center">
      <img class='img-circle' src="/images/brendanryan.jpg" alt="">
      <span class="title">Brendan Ryan</span>
      <span class="tagline">At the intersection of technology and liberal arts<br>
        <a href="mailto:"></a>
      </span>
   </h1>
</div>

<nav class="navbar navbar-default navbar-sticky">
    <div class="container-fluid">

        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="true">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
        </div>

        <div class="navbar-collapse collapse" id="bs-example-navbar-collapse-1">

            <ul class="nav navbar-nav">
            
                
                <li>
                    <a href="/">home</a>
                </li>
                
            
                
                <li>
                    <a href="/bio/">bio</a>
                </li>
                
            
                
                <li>
                    <a href="/repi/">RePi</a>
                </li>
                
            
            </ul>

        </div> 
        
    </div>
</nav>

</header>
    
 
    
<main id="main">

	<div class="container">
		<div class="row topspace">
			<div class="col-sm-8 col-sm-offset-2">

        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">

						</div>
						<h1 class="entry-title">
						  <a href="/repi/table-of-contents/" rel="bookmark">Table of contents</a>
						</h1>
					</header>
					<div class="entry-content">
						<p><a href="./introduction">Introduction</a></p>
<p><a href="./hardware">Hardware</a></p>
<p><a href="./operating-system">Operating system</a></p>
<p><a href="./network-enumeration-and-authentication/">Network enumeration and authentication</a></p>
<p><a href="./storage">Storage</a></p>
<p><a href="./file-sharing-with-samba">File sharing with Samba</a></p>
<p><a href="./containerization-with-docker">Containerization with Docker</a></p>
<p><a href="./maintenance">Maintenance</a></p>
<p><a href="./conclusion">Conclusion</a></p>

					</div>

				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">

						</div>
						<h1 class="entry-title">
						  <a href="/repi/introduction/" rel="bookmark">Introduction</a>
						</h1>
					</header>
					<div class="entry-content">
						<p>The Reproducible Raspberry Pi (RePi) server build project aims to walk you step by step through the stages of building a Raspberry Pi server that is stable, secure and, as the name suggests, reproducible.
The specific setup that will be documented in this tutorial consists of a Raspberry Pi 4 connected to a hard drive array which will serve files directly to devices on the local network and interface with users via other means (specifically through a containerized media player).
At the completion of this project you should have learned some basic Linux commands and have an active understanding regarding the functioning of their server&rsquo;s components.</p>
<p>Reproducibility is of the utmost importance to this project.
The hope is that following the completion of this project were the worst to happen &ndash; be it a hard drive failure, the Pi overheating to the point of no longer functioning, etc. &ndash; you would have the skills to quickly rebuild their server with the least amount of friction and/or data loss.
To achieve this goal, this project relies solely upon easily accessible consumer grade equipment and open-source computer programs, most of which are operated solely via the command line and/or through configuration (config) files.
While this might seem a bit daunting to some, once you learn how to manage your server via the command line, you will be amazed at how easy it is to back up and restore your settings through the power of the written word.
Following this approach, you will no longer need to worry about if they checked the right box in the settings bar, because if you properly backed up your scripts and files, you should be able restore your server to working order by selecting and committing the right text document.</p>
<p>I have two main motivations for creating this project.
First, I too often have found myself copying and pasting lines from tutorials online into my terminal window and watching them return the correct result without actually learning how or why the commands work.
Such a tutorial is not what I intend to create here.
This project should walk you through the process of understanding why certain commands might work better in certain scenarios and why others might be more applicable elswhere.
Second, and on a very related note, I would also like to document the rebuilding of my Raspberry Pi server from the ground up.
I would like to complete my build in the fewest steps possible and allow it to be resilient enough to remain reliable no matter what I throw at it.
And if I do in fact throw too much at it, I would like to have clear documentation about how to get it back to a working state.
My personal goal is to have my server be a nearly disposable appliance (at least regarding software) rather than something held together by love and duct tape that only I can operate.
Regarding the writing of this tutorial, I believe that if I cannot properly explain my motivations for certain choices that I make or if I cannot explain in a step-by-step manner how to complete a task, I must be doing something wrong.
This project should help me document how I created the server that stores the files I depend on every day and should allow you to do the same.</p>
<p>I hope this has piqued the interests of those like me who do not want to worry about breaking their server after installing a new application or running an update.
If so, join me in my journey of creating a Reproducible Raspberry Pi.</p>
<h2 id="unix-philosophy">Unix philosophy</h2>
<p>This project is based around the rather simple yet powerful maxim known as the <a href="https://en.wikipedia.org/wiki/Unix_philosophy">Unix philosophy</a>.
This states that each component in a system should &ldquo;do one thing and do it well&rdquo; while working with other similarly small components to build a bigger structure that produces the end result that you desire.
While this is usually thought of in the realm of software &ndash; one small program does a single calculation and then sends its result to another program which performs another calculation and so on &ndash; the idea of (replaceable) modularity can also be applied to hardware as well: for this build, if any single component &ndash; a cable, a hard drive, the hard drive enclosure and, yes, even the Pi itself &ndash; were to fail, it could be replaced without the entire system failing to the point of not being able to be rebuilt.
Thus, each component has a simple and well-documented job; if it cannot perform that task, it should be and can be replaced.</p>
<h2 id="infrastructure-as-code">Infrastructure as code</h2>
<p>In a similar vein, the idea of <a href="https://en.wikipedia.org/wiki/Infrastructure_as_code">infrastructure as code</a> comes into play.
The idea behind this structure is that information technology (IT) professionals should treat the tools (technological infrastructure) that they use the same way that they treat code by standardizing their hardware and software, iterating (while making sure that they are keeping a record of their changes, a process known as version controlling) and automating tasks instead of performing them manually whenever possible.
The goal of these processes is to produce a more consistent and accurate end result and avoid the idiosyncrasies that individuals may introduce into a system&rsquo;s workflow.
(Mistakes are what make us human.)</p>
<h2 id="command-line-interface">Command line interface</h2>
<p>In order to methodically build our server up from a collection of modular and replaceable components (Unix philosophy) and systematically automate its tasks (infrastucture as code), we must be able to interact with our its operating system.
This tutorial nearly exclusively eludes to physically typing commands into a terminal emulator via the <a href="https://en.wikipedia.org/wiki/Command-line_interface">command line interface</a> (CLI).
There are two main benefits of interacting with a computer via the command line in comparison to a graphical user interface (GUI) that are immediately apparent: (i) it is a more exact way of telling your operating system or an application what you want it to do (anyone who has ever dealt with the pain of trying to specify how big a partition should be using macOS&rsquo;s Disk Utility&rsquo;s pie chart can testify to that), and (ii) it is much more reproducible &ndash; you can easily copy and paste a command that you wrote a year later into a terminal emulator and get the same result (assuming the underlying commands have not changed), while nagivating through pages and pages of settings can really be an exercise in frustration.
I want to be clear about one thing though: using the CLI does take some practice, and there are certain tasks &ndash; especially ones that you do not need to repeat &ndash; that may be more easily done with a GUI.
For instance, you can launch a new Firefox window via the command line, but that is something that I have personally never done, nor can I think of a good reason to ever do.
Use the right tool for the job.</p>
<p>That being said, when trying to steamline the build of a server made of consumer grade parts, I (<a href="https://medium.com/linuxforeveryone/the-real-reason-linux-users-love-the-command-line-e8043f583028">and others</a>) truly believe that the command line and config files are absolutely the best tools for the job.
You cannot copy and paste button presses in a settings menu, but you absolutely can save commands you have entered into a text file to be used at a later date.</p>

					</div>

				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">

						</div>
						<h1 class="entry-title">
						  <a href="/repi/hardware/" rel="bookmark">Hardware</a>
						</h1>
					</header>
					<div class="entry-content">
						<p>The hardware used in this project is based around the Raspberry Pi 4 single-board computer and other consumer grade parts.
The hardware, just like the software in this build tutorial, was chosen because it is easy to find and easy to replace if needed.
Nothing used here is artisan or botique or customed designed; it is there to be used, reused and desposed of as needed.
But do not fret, the end product does not look that bad.</p>
<h2 id="desktop">Desktop</h2>
<p>Throughout this process you will need to be able to communicate with your Raspberry Pi run as a headless server (i.e. without a monitor attached to it) via the command line on a terminal emulator on another computer.
Practically this means that you will need have the Raspberry Pi on the same network as the device with a terminal emulator (e.g. desktop, laptop, Android device with Termux, etc.), preferably plugged into the same router via Ethernet.
The commands that I will be giving through the rest of tutorial are based on Linux. If you do want to follow the tutorial step by step, I suggest that you use a Linux operating system, possibly even by just booting from a <a href="https://en.wikipedia.org/wiki/Live_USB">live USB</a>.</p>
<h2 id="raspberry-pi-4">Raspberry Pi 4</h2>
<p>The <a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/">Raspberry Pi 4 Model B</a> was chosen for this build, as it is pretty much the de facto single-board computer and is widely availble.
As running a server can be pretty demanding, I would absolutely recommend getting either the 4 or 8 GB model.
I do not think that I have ever been limited by RAM with my 4 GB model, but, as with hard drive space, more RAM is better, everything else being equal.</p>
<p>Also, if you ever decide to do something else with your Pi, you can always just erase or remove your microSD card and try something else (like retro gaming, at which the Pi excels).
This is truly the power of chosing a platform that is so widely supported by its manufacturer, third parties and the community at large!</p>
<p>Finally, if you ever get stuck with any problem related to the Raspberry Pi, I would highly recommend that you give a look at the <a href="https://www.raspberrypi.org/documentation/">official documenation</a>.
It is written for beginners but also includes helpful tips for users of all skill levels.
If you have any questions about running a particular program, it may be useful to look at the manual page for that program (e.g. <code>man ls</code>).</p>
<p>As the Raspberry Pi is sold just as a single-board computer, you will also need to purchase a microSD card, case, power supply and drive enclosure with hard disks.</p>
<h2 id="microsd-card">microSD card</h2>
<p>When selecting a microSD card, I looked for one from a reputable brand that is intended to be read from and written to continuously and is considered reliable.
The <a href="https://shop.westerndigital.com/products/memory-cards/sandisk-max-endurance-uhs-i-microsd">SanDisk Max Endurance</a>, marketed to be used for security cameras and dashcams, checked all these boxes for me.
The YouTube channel <a href="https://www.youtube.com/channel/UCbiGcwDWZjz05njNPrJU7jA">ExplainingComputers</a> also has a <a href="https://www.youtube.com/watch?v=YUResed38uo">comparison of different microSD cards for use in single-board computers</a> in which the related SanDisk High Endurance is compared to other microSD cards.</p>
<p>Capacity is not a real constraint in my Raspberry Pi server build, as the microSD card is really only there to host the rather small headless operating system, installed packages and a few other documents, such as config files and data caches.
As such, I am confident that a 32 GB microSD card should be sufficient for most people.</p>
<h2 id="case">Case</h2>
<p>While active cooling (i.e. with a fan) might be perfered to keep the temperature of the board in check, I have never really run into the problem of overheating while using the Raspberry Pi as a simple file server (including for hosting videos that are accessible over my local network).
Thus, I have been perfectly content with the fanless <a href="https://flirc.tv/more/raspberry-pi-4-case">Flirc Raspberry Pi 4 Case</a> with some heat sinks added directly to the board.
Note that running any piece of electronic equipment at a high temperature will shorten its lifespan, so choosing to go fanless may not be right for you.</p>
<h2 id="power-supply">Power supply</h2>
<p>Buying the <a href="https://www.raspberrypi.org/products/type-c-power-supply/">official power supply</a> is definitely the prefered way to go, but I personally really like third-party cables that contain an on&ndash;off switch (instead of unplugging and replugging the power cord to reboot the machine) and the use of a standard USB charger.
Note that if you go this route, you will absolutely need to ensure that the USB power supply meet the minimum requirements (e.g. 3.0A DC output).</p>
<h2 id="sata-drive-enclosure-and-hard-drives">SATA drive enclosure and hard drives</h2>
<p>As the microSD card will not be storing any of the data accessible via the file server, you will need to also attach storage devices to the Raspberry Pi.
For this, I am using standard 3.5&quot; SATA drives in a Mediasonic ProBox (sold under the name fantec in other parts of the world) drive enclosure connected via USB 3 to the Raspberry Pi itself (thus technically making it <a href="https://en.wikipedia.org/wiki/Direct-attached_storage">direct-attached storage (DAS)</a> and not <a href="https://en.wikipedia.org/wiki/Network-attached_storage">network-attached storage (NAS)</a>).
Before I put any new hard drive into long-term use, I run it through <a href="https://github.com/Spearfoot/disk-burnin-and-testing">a grueling <code>badblocks</code> test</a> to make sure that there are no nasty surprises waiting for me in a few days, weeks or months regarding data corruption.
After this, the drives will need to be <a href="https://www.digitalocean.com/community/tutorials/how-to-partition-and-format-storage-devices-in-linux">formatted</a> using a standard file system; I perfer <a href="https://en.wikipedia.org/wiki/Ext4">ext4</a> for maximum compatibility and its journaling capabilities.</p>
<p>While I am not so sure about the long-term use of USB in a server setting, USB-A is rated for <a href="https://web.archive.org/web/20150427001335/http://www.usb.org/developers/docs/devclass_docs/CabConn20.pdf">10,000 cycles of plugging and unplugging</a> (p. 6), so it might just be good enough for home use.</p>

					</div>

				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">

						</div>
						<h1 class="entry-title">
						  <a href="/repi/operating-system/" rel="bookmark">Operating system</a>
						</h1>
					</header>
					<div class="entry-content">
						<p>The operating system is a computer&rsquo;s main intersection point between hardware, software and firmware.
In this build we will mainly be communicating with the Raspberry Pi server&rsquo;s operating system through the use of a <a href="https://en.wikipedia.org/wiki/Terminal_emulator">terminal emulator</a>.
We will for instance tell the operating system to download or install applications (or lower-level firmware or kernel updates), thus affecting the system&rsquo;s software, and even shut down the server via a command, thus physically affecting the hardware&rsquo;s state by use of a terminal emulator.</p>
<p>For me, there are only two real contendors for the choice of an operating system on a Raspberry Pi when it should be used as a server: <a href="https://ubuntu.com/download/raspberry-pi">Ubuntu Server</a> and <a href="https://www.raspberrypi.org/software/operating-systems/">Raspberry Pi OS</a>.
As both operating systems are based on <a href="https://en.wikipedia.org/wiki/Debian">Debian</a>, they function relatively similarly and run much the same software, so the choice as to which operating system to put into production comes down to hardware support.</p>
<p>Raspberry Pi OS was ultimately chosen for this build, as its direct support from the Raspberry Pi Foundation means that it is custom distribution tailored to work with the Pi.
While running Ubuntu Server on the Raspberry Pi is absolutely a possibility, you may run into hiccups along the way.
One such hiccup that heavily influenced my decision to base my server on Raspberry Pi OS is that hardware acceleration for video transcoding with the Jellyfin media server which will be installed below <a href="https://github.com/raspberrypi/firmware/issues/1366#issuecomment-612902082">does not seem to work when using something other than the 32-bit distribution of Raspberry Pi OS</a>.
While I have run Ubuntu Server on my Raspberry Pi for some time and I perfer that I am working with the (<a href="https://ubuntu.com/desktop/statistics">probably, although no exact numbers are shared</a>) most used Linux variant with a 64-bit architecture (<a href="https://www.phoronix.com/scan.php?page=news_item&amp;px=The-32-bit-Ubuntu-20.04-Debs">which has had to fight its way to default status in the Linux world</a>, this server build is not about hacking together working solutions but rather coming up with the quickest way to create a stable server on a Raspberry Pi.
For that, it is clear that <a href="https://rpi-imager-stats.raspberrypi.org/">Raspberry Pi users are using Raspberry Pi OS</a>, so instead of fighting that trend, I have decided to embrace it, with the hope that the <a href="https://www.raspberrypi.org/forums/viewtopic.php?t=275370">64-bit beta version</a> will soon become the standard while still supporting everything that the standard 32-bit version does.</p>
<p>Continuing below, I will show my exact commands using my Ubuntu desktop computer with my desktop labeled as <code>bcmryan@desktop</code> and my Raspberry Pi OS install labeled as <code>pi@raspberrypi</code> (until changed to <code>pi@repi</code> below).
Note also that my path is given immediately following the colon (<code>:</code>), with a tilde (<code>~</code>) representing my <code>/home</code> directory; a following dollar sign (<code>$</code>) means that the command is run with standard privledges, while a pound sign (<code>#</code>) means that the command is being run as <code>root</code>.</p>
<p>Before beginning, it is always a good idea to make sure that you have the latest updates downloaded and installed. The following command means that I will first update (download) all the newest packages without confirmation (<code>--yes</code>) and then fully upgrade (install all downloaded packages; similarly without confirmation, <code>--yes</code>).
Ass two ampersands (<code>&amp;&amp;</code>) are being used in this combined command, the second command will only start once the first command has succesfully completed (thus all packages must be successfully downloaded before the installation process can begin).
Since upgrading and updating both require <code>sudo</code> (temporary <code>root</code>) privledges, I will be prompted for my password (which I input and then confirm with the Enter key; note that you do not get feedback as to how many keys you have entered while inputing a password).</p>
<p><code>bcmryan@desktop:~$ sudo apt update --yes &amp;&amp; sudo apt full-upgrade --yes</code></p>
<p>Now I will download the lastest version of Raspberry Pi OS (which itself is based on Debian 10 Buster) using a permanent link to the most updated version (note that this link may need to change once Debian releases a new version and/or if Raspberry Pi OS&rsquo;s name is changed).
Note the options that are used with <a href="https://en.wikipedia.org/wiki/CURL"><code>curl</code></a>: <code>--location</code> follows the permanent link to its final location; <code>--output</code> following a path ending with a filename and extension determines where to save the file that is being downloaded (in this case an <code>.img</code> image file of Raspberry Pi OS within a compressed <code>.zip</code> file); and finally <code>--write-out %{url_effective}</code> determines the URL that was last fetched (i.e. not the redirect page, but the actual final file to be downloaded).
Before entering the command install <code>curl</code> to make sure it is on your system.</p>
<p><code>bcmryan@desktop:~$ sudo apt install --yes curl</code></p>
<p><code>bcmryan@desktop:~$ curl --location --output ~/Downloads/rpi.zip --write-out %{url_effective} https://downloads.raspberrypi.org/raspios_lite_armhf_latest</code></p>
<p>The on-screen output (standard output, <a href="https://en.wikipedia.org/wiki/Standard_streams#Standard_output_(stdout)">stdout</a>) first shows the redirect to the final URL and then the downloading of the actual file, which takes significantly longer.</p>
<p>Now with image within a <code>rpi.zip</code> file in your <code>Downloads</code> directory, it is time to write the image to the microSD card.
(For extension documentation about writing the image to a microSD card, see the <a href="https://www.raspberrypi.org/documentation/installation/installing-images/linux.md">official documentation</a>.
Note that the documentation also includes information on verifying that the image was properly transfered, which is not included below.)</p>
<p>With your microSD card inserted into your computer (I am using a microSD-to-USB converter, but if you have a SD card slot, a microSD-to-SD converter might work for you), use the <code>lsblk</code> (list block devices) command to see if it is recognized and auto-mounted on your desktop.</p>
<p><code>bcmryan@desktop:~$ lsblk</code></p>
<p>Near the bottom of the list of my block devices, I see that there is a 29.7 GB device that I do not otherwise recognize at <code>/dev/sdd</code> with its partition mounted at <code>/dev/sdd1</code>.
This is my microSD card.
Before I proceed, I will need to unmount the device, as it is considered unsafe to run <a href="https://en.wikipedia.org/wiki/Dd_(Unix)"><code>dd</code></a> on a mounted partition, since other activity (e.g. reading from the device) may otherwise be taking place on that device while <code>dd</code> is writing to it.
That would be bad and could result in corruption.
To unmount a disk, I must specify the mount location, which for me is located in my <code>/media</code> mount location following the pattern <code>/media/bcmryan/1234-5678</code> (with 1234-5678 specifying the eight-digit <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">universally unique identifier</a>, UUID, of a FAT-formatted device).
Note that this requires elevated privledges.</p>
<p><code>bcmryan@desktop:~$ sudo umount /media/bcmryan/1234-5678</code></p>
<p>After umounting the partition, run <code>lsblk</code> again to confirm that it was succesfully unmounted.</p>
<p><code>bcmryan@desktop:~$ lsblk</code></p>
<p>I note that the row beginning with <code>sdd1</code> no longer has a mount point in its final column. That means that the microSD card has been unmounted.
Before we can transfer the data from the computer to the microSD card, we first need to install <code>unzip</code> so that the image within the <code>.zip</code> file can be properly extracted.</p>
<p><code>bcmryan@desktop:~$ sudo apt install --yes unzip</code></p>
<p><strong>Note that the following step uses the infamous <code>dd</code> program.
Please make sure you know what you are doing before continuing.
If you do not feel comfortable continuing, do not.</strong>
Now it is time to write the image file to the microSD card.
The following commmand uses <code>unzip -p</code> to <a href="https://en.wikipedia.org/wiki/Pipeline_(Unix)">pipe</a> the contents of <code>~/Downloads/rpi.zip</code> to the standard input (<a href="https://en.wikipedia.org/wiki/Standard_streams#Standard_input_(stdin)">stdin</a>) of <code>dd</code> which then writes the image to the disk specified with <code>of</code> (output) and with a blocksize (<code>bs</code>) of 4 MB.
To make sure that the contents have been properly copied, <code>dd</code> also flushes (<code>conv=fsync</code>) all data.
The option <code>status=progress</code> displays the status of the writing of the image in the terminal.
Finally, to double-check that the contents have fully been flushed, <code>&amp;&amp; sync</code> is also run (with <code>&amp;&amp;</code> telling the command to only run once the previous command has been properly completed).
<strong>Remember to change your command to the proper disk location (i.e. change /dev/sdd to your microSD card&rsquo;s location in /dev).
The device location I have entered is /dev/sdd (and not the partition location of /dev/sdd1).
Modify your location accordingly, otherwise it may result in data loss.</strong></p>
<p><code>bcmryan@desktop:~$ unzip -p ~/Downloads/rpi.zip | sudo dd of=/dev/sdd bs=4M conv=fsync status=progress &amp;&amp; sync</code></p>
<p>In total, this process may take a few minutes.
Once this process is complete (returning you back to a blank command line), run <code>lsblk</code> again to see where the newly written microSD card is now located and/or mounted.</p>
<p><code>bcmryan@desktop:~$ lsblk</code></p>
<p>Knowing that the two partitions of the microSD card are located at <code>/media/bcmryan/boot</code> and <code>/media/bcmryan/rootfs</code> on my computer named <code>desktop</code>, I can move onto the next step: preparing the microSD card for its first boot.</p>

					</div>

				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">

						</div>
						<h1 class="entry-title">
						  <a href="/repi/network-enumeration-and-authentication/" rel="bookmark">Network enumeration and authentication</a>
						</h1>
					</header>
					<div class="entry-content">
						<p>Network enumeration and authentication are all about knowing which device is which on a network and proving to a device that a user is who they say there are.</p>
<h2 id="ssh">SSH</h2>
<p>In order to issue commands to a server over the network from our local computer, we rely on the Secure Shell Protocol (<a href="https://en.wikipedia.org/wiki/Secure_Shell_Protocol">SSH</a>).</p>
<p>As SSH is not enabled by default in Raspberry Pi OS, it must be activated before the first boot.
[To do this])(<a href="https://www.raspberrypi.org/documentation/remote-access/ssh/README.md),">https://www.raspberrypi.org/documentation/remote-access/ssh/README.md),</a> we are going to <a href="https://en.wikipedia.org/wiki/Touch_(command)"><code>touch</code></a> (in this case create; if a file were to already exist at that location, it would have its access and/or modification date updated) a blank file on the <code>boot</code> partition of our microSD card (which is located in this example at <code>/media/bcmryan/boot</code>).</p>
<p><code>bcmryan@desktop:~$ touch ssh /media/bcmryan/boot</code></p>
<p>It is now time to unmount and physically remove the microSD card from your computer.
Remember to use your correct mount points.</p>
<p><code>bcmryan@desktop:~$ sudo umount /media/bcmryan/boot /media/bcmryan/rootfs</code></p>
<p>Confirm with <code>lsblk</code> that the devices have been unmounted.
To be extra safe before removing the microSD card, it may be worth it to fully power off the USB device with <a href="http://manpages.ubuntu.com/manpages/bionic/man1/udisksctl.1.html"><code>udisksctl</code></a> before physically removing it.</p>
<p><code>bcmryan@desktop:~$ udisksctl power-off --block-device /dev/sdd</code></p>
<h2 id="network-enumeration">Network enumeration</h2>
<p>Now it is time to remove insert the microSD card into the Raspberry Pi for its first boot.
There is just one problem: we know that SSH is enabled and that we should be able to access it, but we do not know the actual local IP address of the server.
No worries, there is a simple Linux command line tool that will help us figure out the IP addresses that are being used on the local network.
From there, you should be able to figure out the IP address that belongs to the Pi.</p>
<p>Now I am going to ping raspberrypi.local, and <a href="https://www.raspberrypi.org/documentation/remote-access/ip-address.md">as long as my desktop supports mDNS</a>, I should be able to find my Raspberry Pi&rsquo;s IP address.
(If you get an error about the hostname not being able to be resolved, see the FAQs below.)</p>
<p><code>bcmryan@desktop:~$ ping raspberrypi.local</code></p>
<p>Great.
Now I see that my Rasbperry Pi has been assinged the dynamic IP address 192.168.0.5.
(<a href="https://en.wikipedia.org/wiki/IP_address#IP_address_assignment">Dynamic IP addresses</a> are given on a first-come-first-served basis, starting from the lowest available number, such as 192.168.0.2, since 192.168.0.1 is usually taken by a router, whereas a static IP address is assigned to a specific device and can be anywhere in the available range of the <a href="https://en.wikipedia.org/wiki/Subnetwork">subnet</a>, from 192.168.0.2 to 192.168.0.255.
The benefits to having a static IP adddress are that you always know the exact location of your device on the network and that no other device will be assigned that address, thus making something such as logging in via SSH much easier.)
Before I can start trying to log in via SSH onto the Raspberry Pi, I will first need to enable SSH.
I do so by installing <code>openssh-server</code>.
From this point on, you should be able to relatively easily use a recent macOS (through the <a href="https://en.wikipedia.org/wiki/Terminal_(macOS)">Terminal app</a>) or Windows 10 (via <a href="https://en.wikipedia.org/wiki/Windows_Subsystem_for_Linux">Windows Subsystem for Linux</a> and/or <a href="https://en.wikipedia.org/wiki/PowerShell">PowerShell</a>) computer, as both systems now support OpenSSH out of the box (but if you have problems, the rest of the tutorial is still geared towards Linux, so you may have to do a bit of troubleshooting to solve your specific problem).</p>
<p><code>bcmryan@desktop:~$ sudo apt install --yes openssh-server</code></p>
<p>The command to SSH into another machine is pretty self explanatory: <code>ssh</code> is followed by the username <code>pi</code> followed by <code>@</code>  (this could be left out if the username were the same as my current user on my desktop, i.e. <code>bcmryan</code>) before the local IP address.</p>
<p><code>bcmryan@desktop:~$ ssh pi@192.168.0.5</code></p>
<p>(An alternative to using the IP address here would be to use the hostname followed by .local, <code>raspberrypi.local</code>, i.e. <code>bcmryan@desktop:~$ ssh pi@raspberrypi.local</code>.
I would not recommend this though as you may run into issues resolving the hostname on other operating systems.
For instance, this method does not work when trying to SSH into the Raspberry Pi while using <a href="https://f-droid.org/en/packages/com.termux/">Termux on Android</a>.)</p>
<p>I am asked if I want to continue, and I physically type in <code>yes</code>.</p>
<p>From here, I am prompted for the password (which is <code>raspberry</code>).</p>
<p>If you have followed me this far, congratulations, you have succesfully logged into a device on your local network via SSH.
And you did so with a terminal, you little hacker, you.</p>
<p>Before we get any futher, the first thing we should do is change the password for the user pi on the Raspberry Pi.
To do so, simply follow the prompt you are first shown while logging in with the command <code>passwd</code>.</p>
<p><code>pi@repi:~$ passwd</code></p>
<p>Enter your current password (<code>raspberry</code>) and a new password twice (for this documentation, I will be using <code>passwordpi</code>, as there will be a few passwords that will be set throughout; of course you should use a much more secure password on your machine).</p>
<p>Now, before we do anything else, it is important to make sure that this newly installed system is fully up to date.
To do this, we first can update our system via <code>apt</code>.</p>
<p><code>pi@raspberrypi:~$ sudo apt update --yes &amp;&amp; sudo apt full-upgrade --yes</code></p>
<p>You may have noticed that you are not prompted for a password when connected to your server via SSH.
It is definitely nice to not need to enter it so many times, but you also need to remember that entering a password is a security feature, so you may want to double-check even more thoroughly before entering a command with <code>sudo</code>.</p>
<p><a href="https://en.wikipedia.org/wiki/Network_enumeration">Network enumeration</a> is the act of gathering information about the devices, users, etc. within a network, and with a bit of planning, you can make the job much easier for yourself in the future.
For instance, coming up with a good <a href="https://en.wikipedia.org/wiki/Computer_network_naming_scheme">network naming scheme</a> will allow you to give your devices a hostname (the <code>desktop</code> or <code>raspberrypi</code> that follows the username in the commands throughout) and/or local static IP address (<code>192.168.0.XYZ</code>) that is meaningful to you and/or your organization.</p>
<p>My personal hostnames are based on <a href="https://en.wikipedia.org/wiki/List_of_dinosaur_genera">genus names of dinosaurs</a> that end in -saurus.
My thinking behind this goes that my personal network will never run out of the 1000 or so genus names of Dinosauria ending in -saurus.
Additionally, I can give my devices names that fit characteristics of that device: my desktop is actually called <code>tyrannosaurus</code>, as it is the king of all devices on my network.
Were I to upgrade my computer, I could continue calling it <code>tyrannosaurus</code>, or I could choose to retire the name (<a href="https://en.wikipedia.org/wiki/Ship_of_Theseus">because there might be a limit to how many components can be changed before an object is no longer the same object</a>) and call it <a href="https://en.wikipedia.org/wiki/Tarbosaurus"><code>tarbosaurus</code></a> or <a href="https://en.wikipedia.org/wiki/Zhuchengtyrannus"><code>zhuchengtyrannus</code></a>, <a href="https://en.wikipedia.org/wiki/Tyrannosauridae">genera also belonging to the taxonomic family of the tyrant king</a>.
This is very clearly a silly excercise that I have undertaken, but I found it to be rewarding, and it has kept me from needing to rename my computer <code>desktopoffice</code>, <code>ubuntu2004</code> or <code>bcmryan1</code> whenever a physical machine changes location, operating system or owner.
Of course on a larger scale, this is untenable.
In this regard, do as I say, not as I do.
For a home with a few connected devices, naming machines based on fun charactersitics might be feasible, but once printers, routers, terminals, etc. are involved in a multinational corporation with branches on different levels, inside different buildings and within different cities, it is absolutely vital to come up with a more sustainable naming scheme, potentially based on device type and location (preferably not owner, as this is bound to change much more frequently than an office building&rsquo;s address).</p>
<p>Similarly, all static IP addresses within my network have some kind of meaning.
I have reserved the first 20 IP addresses (up to 192.168.0.19) for dynamic addresses, including all those devices which might hop on and off without having been assigned a static IP address (e.g. a tablet which I am testing out but which has not yet been configured).
From there, every current (and potentially future) member of my household gets 10 IP addresses.
This is where 192.168.0.20 and 192.168.0.25 from earlier come into play: those are my my main desktop (20) and my phone (25).
These personal addresses end at 192.168.0.99, and I have reservered 192.168.0.100 for this server.
I hope that this IP addressing scheme will continue to serve me well, as I have yet to run into any problems.
Of course, this would be a completely useless excercise if I did not have proper documentation to tell me which IP address is allocated to which person (dynamic, bcmryan, etc.), under which hostname (e.g. <code>tyrannosaurus</code>) on which device (e.g. processor type in desktop computer).
I have found this information incredibly easy to store in a simple spreadsheet on my computer so that I never have to wonder what the IP address is of any computer I am trying to connect to via SSH.
How to change a computer&rsquo;s or smartphone&rsquo;s static IP address will of course depend on your device&rsquo;s operating system, be it <a href="https://help.ubuntu.com/stable/ubuntu-help/net-manual.html.en">Ubuntu</a>, <a href="https://support.microsoft.com/en-us/windows/change-tcp-ip-settings-bd0a07af-15f5-cd6a-363f-ca2b6f391ace">Windows</a>, <a href="https://support.apple.com/guide/mac-help/use-dhcp-or-a-manual-ip-address-on-mac-mchlp2718/11.0/mac/11.0">macOS</a>, <a href="https://support.apple.com/en-us/HT202693">iOS</a> or <a href="https://www.businessinsider.com/how-to-change-ip-address-on-android">Android</a>.
(If you have a link to official Android documentation regarding setting an IP address, please let me know, and I will include it here.)</p>
<p>Now that we have logged into the Raspberry Pi, it is a good time to change the hostname and set a static IP address so that we always know where to find the machine on our local network.</p>
<h2 id="hostname">Hostname</h2>
<p>Changing a hostname can be completed using the very easy-to-use <a href="http://manpages.ubuntu.com/manpages/focal/man1/hostnamectl.1.html">hostnamectl</a> on both Raspberry Pi OS and Ubuntu Server.
Simply enter <code>hostnamectl set-hostname</code> followed by the new hostname.</p>
<p><code>pi@raspberrypi:~$ hostnamectl set-hostname repi</code></p>
<p>You will be asked for your password, and after you enter it, the hostname will be changed, although you will notice that the old hostname is still in use on the command line once you exit.
That is ok.
It will change once the system is rebooted after we change the static IP address.</p>
<p>To make sure that the hostname has been changed throughout the machine, <a href="https://www.cyberciti.biz/faq/ubuntu-change-hostname-command/">you should also edit the file /etc/hosts</a> and update the bottommost line with the old hostname.
To do this, we will use a CLI text editor such as <code>nano</code> with <code>sudo</code> privileges.
(<a href="https://en.wikipedia.org/wiki/Editor_war">Arguments can be very heated regarding text editors!</a>)</p>
<p><code>pi@raspberrypi:~$ sudo nano /etc/hosts</code></p>
<p>Use your down arrow key to select the appropriate line and the right arrow key to edit it.
Delete raspberrypi and replace it with repi.
Save the new document with Ctrl+S, and exit with Ctrl+X.</p>
<h2 id="static-ip">Static IP</h2>
<p>As I have stated before, by default, the Raspberry Pi is allocated a dynamic IP address.
The good news is that <a href="https://www.raspberrypi.org/documentation/configuration/tcpip/README.md">Raspberry Pi OS makes it relatively straightforward to set a static IP address</a>. (It should be noted that this is different than <a href="https://ubuntu.com/server/docs/network-configuration">setting an IP address on Ubuntu Server</a>.)</p>
<p>But to show the power of the command line, we will instead just text append (add text to the end of a text file) using <a href="https://en.wikipedia.org/wiki/Tee_(command)"><code>tee</code></a>.
The following command will append the configuration via <code>tee -a</code> with <code>sudo</code> privileges to <code>/etc/dhcpcd.conf</code> while defining <code>eth0</code> (Ethernet) as the interface we would like to use with the static IP address 192.168.0.100 with a router at 192.168.0.1 and Google&rsquo;s DNS server at 8.8.8.8.
A title can be given to the configuration with a title (Static IP configuration) following a hash (#), which notes that what follows on that line is a comment.
END on both sides of new lines act as bookmarks to show which text should be appended, and the two less-than signs point to the file to which the text should be appended.</p>
<pre><code>pi@raspberrypi:~$ sudo tee -a /etc/dhcpcd.conf &lt;&lt; END

# Static IP configuration:
interface eth0
static ip_address=192.168.0.100/24    
static routers=192.168.0.1
static domain_name_servers=8.8.8.8
END
</code></pre><p>After entering the command, you will be warned that the host raspberrypi does not exist.
That is completely accurate, as we just changed the hostname, but do not worry, this is not a problem, and your new hostname and static IP address will work fine.</p>
<p>To verify that the text has been correctly added to <code>/etc/dhcpcd.conf</code>, you can see the files contents by using the <a href="https://en.wikipedia.org/wiki/Cat_(Unix)"><code>cat</code></a> (concatenate) command.</p>
<p><code>pi@raspberrypi:~$ cat /etc/dhcpcd.conf</code></p>
<p>From here, we need to reboot the Raspberry Pi to have all changes take effect.</p>
<p><code>pi@raspberrypi:~$ sudo reboot</code></p>
<p>Before we try logging onto the Raspberry Pi for the first time with the new static IP address (192.168.0.100), it is a good idea to delete fingerprint that we accepted for the old dynamic IP address (192.168.0.5).
Otherwise, there may be problems in the future if you ever try to SSH into another machine that shares the same dynamically given IP address.
<strong>This is potentially dangerous if you use SSH with multiple devices, so make sure that you know which fingerprint of which IP address you are deleting.</strong></p>
<p><code>bcmryan@desktop:~$ ssh-keygen -f &quot;/home/bcmryan/.ssh/known_hosts&quot; -R &quot;192.168.0.5&quot;</code></p>
<p>Now we it is time to cross our fingers and try to log onto the Raspberry Pi with a static IP address.</p>
<p><code>bcmryan@desktop:~$ ssh pi@192.168.0.100</code></p>
<p>To accept the new fingerprint, physically type in <code>yes</code>.
To complete the login, enter in the password.</p>
<p>And it was successful!
The Raspberry Pi is now on its statically given IP address of 192.168.0.100, and the command line now reads <code>pi@repi:~$</code>.
What is also neat is that the IP address of the desktop from which you connected via SSH to the Raspberry Pi is also shown.
In my case, that is 192.168.0.20.
Having a logical system in place for IP addresses tells me that I last succesfully logged in from the desktop that I am working from.</p>
<h2 id="ssh-keys">SSH keys</h2>
<p>We usually authenticate our identity using a password, but that is not the only way (as you may know from certain applications that require a fingerprint or <a href="https://en.wikipedia.org/wiki/Multi-factor_authentication">multi-factor authentication</a> for which you for instance have to verify your identity with a password and a SMS or email code).
Authentication for SSH can be done through at least two different methods, by use of a password and/or a key.
With password authentication, you are tell your desktop through a terminal command that you would like to log on to a server (or other remote machine) at a specific IP address with a certain username.
Just like when entering a command with <code>sudo</code>, you are asked for the password of that other user on that other machine.
With authentication via SSH keys, it is not required that you provide a password (although you can enable two-factor authentication requiring a password).
Instead, a private key (which is just a text file with a few hundred random characters) saved onto your desktop sees if it fits to a public key saved on the server.
Although these two keys are not identical, if a specific algorithm determines that they are a match, you can log on via your desktop to to the server.</p>
<p>In this section, we are going to share SSH keys between the desktop and Raspberry Pi server so that we no longer need to type in a password following the command <code>ssh pi@192.168.0.100</code>.
Following the <a href="https://www.raspberrypi.org/documentation/remote-access/ssh/passwordless.md">official documentation</a> we are going to first generate new SSH keys on the desktop with <code>ssh-keygen</code>.</p>
<p><code>bcmryan@desktop:~$ ssh-keygen</code></p>
<p>You will be asked where to save the key.
Hit enter to save it in its default location (this will create a public key at <code>~/.ssh/id_rsa.pub</code> and a private key at <code>~/.ssh/id_rsa</code> on the desktop).
You will also be asked for a passphrase.
You may choose to not enter anything here (it encrypts the key) and accept the default setting by again hitting enter.
Enter your passphrase again and/or hit enter to continue.</p>
<p>Now you will share public key with your server with <code>ssh-copy-id</code>.
This will log you into the user (<code>pi</code>) given at the IP address (192.168.0.100).
It is of course important that the static IP address is set at this point so that the desktop shares the key with the correct server and that its address does not change, which would cause problems while attempting to connect at a later time.</p>
<p><code>bcmryan@desktop:~$ ssh-copy-id pi@192.168.0.100</code></p>
<p>Once we enter the command, we are prompted for the password of user <code>pi</code> on 192.168.0.100.
This is the password that was set above, i.e. <code>passwordpi</code> (thus adding the contents of the public key on the desktop at <code>~/.ssh/id_rsa.pub</code> to the Raspberry Pi at <code>~/.ssh/authorized_keys</code>).</p>
<p>From here, you should be able to SSH into the Raspberry Pi server (provided that both the desktop and server have static IP addresses) without being prompted for a password.</p>
<p><code>bcmryan@desktop:~$ ssh pi@192.168.0.100</code></p>
<p>And it worked!
Although <code>ssh-copy-id</code> will not natively run on Windows 10 using PowerShell, there is a <a href="https://www.chrisjhart.com/Windows-10-ssh-copy-id/">work-around PowerShell one-line script</a> that affectively does the same thing by copying the contents of <code>$env:USERPROFILE\.ssh\id_rsa.pub</code> (the Windows equivalent of <code>~\.ssh/id_rsa.pub</code>) on a Windows desktop and appending (<code>cat &gt;&gt;</code>) it to <code>~/.ssh/authorized keys</code> on the Raspberry Pi server.</p>
<p><code>PS C:\Users\bcmryan&gt; $env:USERPROFILE\.ssh\id_rsa.pub | ssh pi@192.168.0.100 &quot;cat &gt;&gt; .ssh/authorized_keys&quot;</code></p>
<p>To recap, we can now access the terminal emulator as user <code>pi</code> of the Raspberry Pi server with a hostname of <code>repi</code> and a static IP of 192.168.0.100 across the local network using SSH without needing to enter a password.
That is pretty spectacular, and we are well on our way to being able to set up and administer a full server.</p>

					</div>

				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">

						</div>
						<h1 class="entry-title">
						  <a href="/repi/storage/" rel="bookmark">Storage</a>
						</h1>
					</header>
					<div class="entry-content">
						<p>With the base of the system set up, the next component to add your Raspberry Pi server to get it off the ground as a file server is storage.
As stated above, this tutorial follows the following setup: an array of hard drives (which do not need to be from the same manufacturer or of the same size; formatted in this example as ext4) inside an enclosure connected to the Raspberry Pi via USB 3.
In this section we will merge the indepedent file systems so as to make your Raspberry Pi show a continuous file system (thus, for instance, four 8 TB hard drives would appear as a single 32 TB file system making it much easier to point a media server to a single directory instead of needing to add multiple).</p>
<h2 id="user-permissions">User permissions</h2>
<p>Before we even start with the process of merging file systems, it is a good idea to create two users and one group on the system that serve a singular purpose: to be own the files on the hard drives.
Without going too far into <a href="https://en.wikipedia.org/wiki/File-system_permissions">file system permissions</a>, our purpose is to create one user who has read and write access to the files and another user who can only read them.
These two users will belong to the same group.
This will allow us to grant read-write permissions to certain applications or when we specifically request them while defaulting to read-only permissions if we do not want to change anything.
This, for instance, can protect against data loss if a program, such as Jellyfin, which will be installed below, <a href="https://www.reddit.com/r/jellyfin/comments/f6hwsr/jellyfin_deleting_files/">attempts to delete user data</a>, due to either user or system error.
Regardless of who is at fault for a specific error, if a program does not have read-write access to a directory, it cannot modify it.</p>
<p>Using the <a href="http://manpages.ubuntu.com/manpages/focal/man8/groupadd.8.html"><code>groupadd</code></a> command, we are going to create the group storage with the specific GID (<code>--gid</code>; group identification number) 200 as a system (<code>--system</code>) group.
Having a preset GID comes in handy when granting specific programs (such as Jellyfin) the permissions of a certain group.
A <a href="https://askubuntu.com/a/524010">system group is not inherently different from a normal group</a> but is conventionally used for technically processes, not users.
For instance, no human user will belong to the group storage, as it is solely to resolve or avoid permission issues, whereas a group called family might allow multiple users on a Linux computer to share photos with one another in a single directory, with each user being able to add, modify or deletes files therein.</p>
<p><code>pi@repi:~$ sudo groupadd --system --gid 200 storage</code></p>
<p>Similarly, we now create two users belonging to the group storage: storagerw (rw for read-write permissions; this one will be the owner of our shared directory) and storagero (ro for read-only permissions; this one will belong to the group storage and thus be given permission to access files but not modify or delete them).
Using the <a href="http://manpages.ubuntu.com/manpages/focal/man8/useradd.8.html"><code>useradd</code></a> command, for the same reasons as above we specify the UID (<code>--uid</code>; user identification number) and GID (<code>--gid</code>; so that both accounts belong within the group storage with a GID of 200) and set both accounts as system accounts (<code>--system</code>).
Note that user storagerw is given the UID 200, while user storagero is 201.
This should be somewhat memorable: the UID that matches the GID has read-write permissions, while the UID that is slightly different is a single number off.</p>
<p><code>pi@repi:~$ sudo useradd --system --uid 200 --gid 200 storagerw &amp;&amp; sudo useradd --system --uid 201 --gid 200 storagero</code></p>
<p>So that no one attempts to log in using these user accounts (potentially to gain access to the system), we can lock them with the <code>usermod</code> command and the <code>--lock</code> option (repeated for both users).</p>
<p><code>pi@repi:~$ sudo usermod --lock storagerw &amp;&amp; sudo usermod --lock storagero</code></p>
<p>To confirm that the new user accounts have been properly added to the group storage and to confirm their UID, we can use the <code>id</code> command followed by the user name (repeated for both users).</p>
<p><code>pi@repi:~$ id storagerw &amp;&amp; id storagero</code></p>
<p>To verify that both accounts are system accounts (and thus not intended for human use), if you list the directories in <code>/home</code>, you will note that only user pi is given a <code>/home</code> directory.
For the <a href="https://en.wikipedia.org/wiki/Ls"><code>ls</code></a> (list) command, note that I perfer adding the options for horizontally (<code>l</code>) listing all (<code>a</code>; thus including hidden files) directories and files with human-readable (<code>h</code>; thus in kilobytes, megabytes, etc., not bytes) file sizes.</p>
<p><code>pi@repi:~$ ls -lah /home</code></p>
<h2 id="mergerfs">mergerfs</h2>
<p>Following <a href="https://blog.linuxserver.io/2017/06/24/the-perfect-media-server-2017/">The Perfect Media Server 2017</a> build guide (along with its <a href="https://www.youtube.com/watch?v=tbCMfm-jJ5Y">accompanying YouTube video</a> and <a href="https://perfectmediaserver.com/tech-stack/mergerfs/">general information on mergerfs</a>; from which this section is very heavily inspired, including many commands), we install <a href="https://github.com/trapexit/mergerfs">mergerfs</a>, a union file system that allows for individual block storage devices (e.g. hard drives) to appear as a single device to the operating system and programs.
As stated in the <a href="https://github.com/bcmryan/repi#storage">Storage</a>, this allows for four individual drives, including those of different sizes and from different manufacturers, to be housed in a single directory.
Thus, instead of needing to add four different paths to a media server (i.e. one for each hard drive), you can add a single path which combines all the hard drives in one directory.</p>
<p>Now, aftering confirming that your enclosure with hard drives installed is physically connected to the Raspberry Pi, turn on the enclosure.
If you run <code>lsblk</code>, you will notice that your individual drives are not listed.
This is exactly as it should be because the devices have not been given a mount point.
To confirm that your Raspberry Pi sees the hard drives, you should instead run <code>sudo blkid</code> (block device identification).</p>
<p><code>pi@repi:~$ sudo blkid</code></p>
<p>Here you are shown all block devices connected to your Raspberry Pi first identified by their location as a <code>/dev</code> directory followed by information such as their label, UUID (an ID that identifies a specific block device and will probabistically never be used for another block device), type (i.e. file system), etc.
The devices that represent the attached hard drives with be listed as e.g. <code>/dev/sda1</code> to <code>/dev/sdd1</code> for four devices with a single partition each.
I know that my enclosure lists the hard drives from top to bottom, i.e. with the topmost hard drive as <code>/dev/sda1</code> and the bottommost as <code>/dev/sdd1</code>.
If you are also so lucky as to have standardized scheme, it may help you to physically group your hard drives so that you know which data are held in a specific area (e.g. with the top two hard drives holding only family photos so that you know that all photos are in <code>/dev/sda1</code> and <code>/dev/sdb1</code>).
You should now note the UUID of each hard drive, as these will be used below.</p>
<p>Before beginning, you must install mergerfs and fuse via <code>apt</code>.</p>
<p><code>pi@repi:~$ sudo apt install --yes mergerfs fuse</code></p>
<p>Now it is time to create mount points for all the hard drives.
To do this, we use the <code>mkdir</code> (make directory) command with elevated privileges in the <code>/mnt</code> (mount) directory to create directories for each individual hard drive and a combined directory for all hard drives together.
Using a feature of the <a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)">Bash</a> shell (the command line interpreter into which you have been typing) called <a href="https://en.wikipedia.org/wiki/Bash_(Unix_shell)#Brace_expansion">brace expansion</a>, you can create multiple directories at once so long as the unique parts are entered within curly brackets and separated with commas.
For this example, I am creating 16 directories with 10 representing the content stored on each of the hard drives, 5 representing parity drives for use with SnapRAID and 1 representing the combined contents of all others via mergerfs: <code>/mnt/diskMovies1</code> to <code>/mnt/diskMovies5</code>, <code>/mnt/diskSeries1</code> to <code>/mnt/diskSeries5</code>, <code>/mnt/parity1</code> to <code>/mnt/parity5</code> and <code>/mnt/storage</code>.
Note that as my hard drives only hold media (backups of my extensive DVD and Blu-Ray collection, which is <a href="https://en.wikipedia.org/wiki/Ripping#Legality">legal in my jurisdiction</a>), I am labeling the hard drive locations according to the type of media they are holding (i.e. movies and series).
(Note also that my files are structured according to Jellyfin standards for <a href="https://jellyfin.org/docs/general/server/media/movies.html">movies</a> and <a href="https://jellyfin.org/docs/general/server/media/shows.html">shows</a>.)
You should of course modify this to meet your individual needs (e.g. if you are hosting family photos and documents, <code>/mnt/diskPhoto</code> and <code>/mnt/diskDoc</code>).
(Labeling the directories with trailing numbers and creating more directories than I have hard drives give me flexibility were I to combine two hard drives into a single one with a larger capacity or add more drives in a larger enclosure.)</p>
<p><code>pi@repi:~$ sudo mkdir /mnt/{disk{Movies,Series}{1,2,3,4,5},parity{1,2,3,4,5},storage}</code></p>
<p>From here, it is time to automatically mount the hard drives when the Raspberry Pi boots up and merge the contents into one directory, namely <code>/mnt/storage</code>.
To do this, we have to add entries to <a href="https://en.wikipedia.org/wiki/Fstab"><code>fstab</code></a> (file systems table; at <code>/etc/fstab</code>).
The entries include the UUID noted earlier, mount location (e.g. <code>/mnt/diskMovies1</code>), file system type (which is assumed to be ext4), options, dump and pass.
We add the following information (of course with your individual UUIDs replacing longstring) to <code>/etc/fstab</code> with the <code>tee</code> command as in <a href="https://github.com/bcmryan/repi#static-ip">Static IP</a>.
The final line is the actual mergerfs setup.
The first column groups all directories that begin with <code>/mnt/disk</code> (using the <a href="https://en.wikipedia.org/wiki/Glob_(programming)">globbing wildcard asterisk</a> to signify anything or nothing following) and mounts them together in <code>/mnt/storage</code> (second column) as the file system fuse.mergerfs (third column).
The fourth column lists options following the default setup in the <a href="https://github.com/trapexit/mergerfs">mergerfs documentation</a> with certain changes: first, option cache.files=off is removed, as it is not recognized via the standard upstream installation with <code>apt</code>; second mergerfs is now path perserving (i.e. if a directory already exists, a newly created file will go into the directory on the same hard drive instead of making a new directory on a different hard drive); and third it has been given the name mergerfs when listed using <code>df -h</code> (disk free space in human-readable terms).
Finally, dump and pass are both left as 0.</p>
<pre><code>pi@repi:~$ sudo tee -a /etc/fstab &lt;&lt; END

# Mount points for individual hard drives for use with mergerfs at /mnt/disk{Movies,Series}{1,2,3,4,5}
UUID=longstring /mnt/diskMovies1 ext4 defaults 0 0
UUID=longstring /mnt/diskMovies2 ext4 defaults 0 0
UUID=longstring /mnt/diskMovies3 ext4 defaults 0 0
UUID=longstring /mnt/diskSeries1 ext4 defaults 0 0

# mergerfs mount point at /mnt/storage
/mnt/disk* /mnt/storage fuse.mergerfs allow_other,use_ino,dropcacheonclose=true,category.create=epmfs,fsname=mergerfs 0 0
END
</code></pre><p>You can confirm that <code>/etc/fstab</code> has been correctly edited using the <code>cat</code> command.</p>
<p><code>pi@repi:~$ cat /etc/fstab</code></p>
<p>Now to mount all devices according to the entries in <code>/etc/fstab</code> (i.e. mount the drives we just defined into their new mount points), use the <code>mount</code> command with the <code>--all</code> option with elevated privileges.</p>
<p><code>pi@repi:~$ sudo mount --all</code></p>
<p>To verify that all directories have been properly mounted, list all directories in <code>/mnt</code> and you will see that the mounted directories are no longer owned by user root and group root.</p>
<p><code>pi@repi:~$ ls -lah /mnt</code></p>
<p>To view the new combined directory of <code>/mnt/storage</code>, list all directories in <code>/mnt/storage</code>.</p>
<p><code>pi@repi:~$ ls -lah /mnt/storage</code></p>
<p>Now that we can access all directories and files in the merged directory of <code>/mnt/storage</code>, it is time to use the <code>chown</code> (change owner) command with the <code>--recursive</code> option and elevated privileges to define user storagerw and group storage as the directory&rsquo;s owner.
Keeping the default permissions (<code>drwxr-xr-x</code>, shown when using <code>ls -lah /mnt</code> annd looking at <code>/mnt/storage</code>), this means that user storagerw will have read-write (and execute) privileges, while anyone belonging to group storage (such as user storagero) will only be able to read (and execute) from the directory but neither modify, delete nor create files or directories within it.
For this command, you can either specify the UID and GID (i.e. 200:200) or the user&rsquo;s and group&rsquo;s name (storagerw:storage).
Note that depending on how many directories and files are stored within <code>/mnt/storage</code>, this may take a few minutes (as it needs to change the permissions on every individual directory and file).</p>
<p><code>pi@repi:~$ sudo chown --recursive storagerw:storage /mnt/storage</code></p>
<p>Once you are returned to a blank command line, you can now see the changes to the ownership of <code>/mnt/storage</code> by listing all directories in <code>/mnt</code>.
Additionally, you will notice that all directories that merge into <code>/mnt/storage</code> also are now owned by user storagerw and group storage.</p>
<p><code>pi@repi:~$ ls -lah /mnt</code></p>
<p>Due to the change in permissions, user pi (the one which we are using) can read but not modify, delete or create files within <code>/mnt/storage</code>.
This is not a problem, as one can always elevate their privileges with <code>sudo</code> to be able to have read-write permissions or grant themselves permission by specifying which user to use for a certain application (this functionality is called <a href="https://www.samba.org/samba/docs/current/man-html/smb.conf.5.html#FORCEUSER">force user</a> and <a href="https://www.samba.org/samba/docs/current/man-html/smb.conf.5.html#FORCEGROUP">force group</a> for Samba and <a href="https://docs.linuxserver.io/general/understanding-puid-and-pgid">PUID and PGID</a> for Docker containers from <a href="https://www.linuxserver.io/">LinuxServer.io</a>).</p>
<h2 id="snapraid">SnapRAID</h2>
<p>This section is currently empty, as I have not yet had the opportunity to configure SnapRAID.
For now, you may want to view the <a href="http://www.snapraid.it/">official SnapRAID website</a> and <a href="https://github.com/amadvance/snapraid">Github page</a> and the tutorial for <a href="https://blog.linuxserver.io/2017/06/24/the-perfect-media-server-2017/">The Perfect Media Server 2017</a> build guide (along with its <a href="https://www.youtube.com/watch?v=Ir5ZsUIbHXA">accompanying YouTube video</a>).</p>

					</div>

				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">

						</div>
						<h1 class="entry-title">
						  <a href="/repi/file-sharing-with-samba/" rel="bookmark">File sharing with Samba</a>
						</h1>
					</header>
					<div class="entry-content">
						<p>With a central directory merging all of your large storage drives together, it is time to make them accessible over your local network with <a href="https://en.wikipedia.org/wiki/Samba_(software)">Samba</a>, a reimplementation of the <a href="https://en.wikipedia.org/wiki/Server_Message_Block">Server Message Block SMB protocol</a>.
Although SMB usually is targeted at use with Windows computers, as it allows for networking between Windows, Linux and macOS (all of which are represented in my house), it is what I use on my local network.
(A commonly used alternative in the Linux world is <a href="https://en.wikipedia.org/wiki/Network_File_System">Network File System, NFS</a>.)</p>
<p>Before you can begin to share the contents of your file system across your local network, you must first install <code>samba</code> via <code>apt</code>.
I have included lines above to automatically answer the question &ldquo;Modify smb.conf to use WINS settings from DHCP?&rdquo; to &ldquo;No&rdquo; by use of <a href="http://manpages.ubuntu.com/manpages/bionic/man1/debconf-set-selections.1.html"><code>debconf-set-selections</code></a> (see <a href="https://unix.stackexchange.com/questions/546470/skip-prompt-when-installing-samba)">https://unix.stackexchange.com/questions/546470/skip-prompt-when-installing-samba)</a>.</p>
<pre><code>pi@repi:~$ echo &quot;samba-common samba-common/workgroup string WORKGROUP&quot; | sudo debconf-set-selections
pi@repi:~$ echo &quot;samba-common samba-common/do_debconf boolean true&quot; | sudo debconf-set-selections
pi@repi:~$ echo &quot;samba-common samba-common/dhcp boolean false&quot; | sudo debconf-set-selections
pi@repi:~$ sudo apt install --yes samba
</code></pre><p>As there are a number of depdencies to install, this may take a minute.
The next step is to save a copy of the original Samba config file at <code>/etc/samba/smb.conf</code>.
As this file acts more like documentation than configuration, it is best to keep a copy of it were you to ever need to look at it again.
To do so, use the <code>mv</code> (move; also for renaming files) command with elevated privileges to rename the file as <code>/etc/samba/smb.conf.bak</code> (<code>.bak</code> is a commonly used file extension for backups; and there is no need to worry that this file is now not able to be accessed, Linux still knows that this is a text file, unlike a Windows machine, for instance).</p>
<p>To write a new <code>/etc/samba/smb.conf</code>, we will again use <code>tee</code>.
The exact parameters are defined in the <a href="https://www.samba.org/samba/docs/current/man-html/smb.conf.5.html">official documentation</a>, so I will only summarize them here.
For global (thus for all Samba shares, even though only <code>[storage]</code> is defined here) the <code>map to guest = Bad User</code> option means that users, whether they have a valid username or not, can be given guest access.
Logs are kept in the directory <code>/var/log/samba/</code>, although <code>log level = 1</code> means that extensive logging needed for debugging is not provided.
The share defined here is called <code>[storage]</code> and allows access to files at <code>path = /mnt/storage</code>.
The option <code>guest ok = yes</code> means that anyone can access the share (even those without an account), but <code>read only = yes</code> means that general users are given read-only access.
Read-write access, on the other hand, is given to user storagerw through the option <code>write list = storagerw</code>.
To avoid permissions issues, the options <code>force user = storagerw</code> and <code>force group = storage</code> are set so to the same user and group that owns <code>/mnt/storage</code>; note, however, that this still requires a user to be on the <code>write list</code>, or else they are given read-only access.
Comments can be used throughout with the use of a hash.</p>
<pre><code>pi@repi:~$ sudo tee -a /etc/samba/smb.conf &lt;&lt; END
[global]
        map to guest = Bad User
        log file = /var/log/samba/%m.log
        log level = 1

[storage]
        # Public read access and read-write access for storagerw.
        path = /mnt/storage
        guest ok = yes
        read only = yes
        write list = storagerw
        force user = storagerw
        force group = storage
END
</code></pre><p>As storagerw is now a defined user for the Samba share, you need to define this user&rsquo;s password.
To do this, use the <a href="https://www.samba.org/samba/docs/current/man-html/smbpasswd.8.html"><code>smbpasswd</code></a> command with option <code>-a</code> to specify that this is a new password.
When prompted for a password (and when prompted to repeat it), for this tutorial, I am using <code>passwordsamba</code>.
But this is an absolutely terrible password, and you should use your own.</p>
<p><code>pi@repi:~$ sudo smbpasswd -a storagerw</code></p>
<p>Now, for the next step, you should switch to your Linux desktop.
(Here are steps for <a href="https://www.techrepublic.com/article/how-to-connect-to-linux-samba-shares-from-windows-10/">Windows 10</a> using <code>//192.168.0.100/storage</code> and <a href="https://www.techrepublic.com/article/how-to-connect-your-macos-device-to-an-smb-share/">macOS</a> using <code>smb://192.168.0.100/storage</code>.
Again, I would appreciate links to official documentation if they exist.)
Here you will define your local user as the Samba user storagerw so that your desktop has read-write permissions to the Samba share.
Thus your desktop will be the only one able to create, modify or delete directories or folders on the Raspberry Pi&rsquo;s share at <code>/mnt/storage</code>, but all other users on all other computers will be able to access it.
This may be useful depending on how your Samba share is to be used.
I, for instance, may want anyone on the network to be able to access all of the files in a specific share (of, say, family pictures), but to protect against data loss, I may only want a single user on a single computer to be able to create, modify or delete those pictures.
That way, if a family member comes over to visit, they can view the photos using their device, but we can be sure that no one will accidently delete them.
Following <a href="https://wiki.ubuntu.com/MountWindowsSharesPermanently">Ubuntu&rsquo;s documentation</a>, the first step is to install <code>cifs-utils</code> via <code>apt</code>.
(<a href="https://en.wikipedia.org/wiki/Server_Message_Block#SMB_/_CIFS_/_SMB1">The name CIFS actually refers to SMB 1</a> from 1983 &ndash; Windows 10 introduced SMB 3.1.1 &ndash; but it seems to have stuck around.)</p>
<p><code>bcmryan@desktop:~$ sudo apt install --yes cifs-utils</code></p>
<p>From here, you need to create a mount point (directory) for the share using <code>mkdir</code> with elevated privileges.
I will be using <code>/mnt</code>, as this standard directory for moint points that do not change (unlike <code>/media</code> which is for removable devices like USB drives).</p>
<p><code>bcmryan@desktop:~$ sudo mkdir /mnt/repi</code></p>
<p>As this directory was created with <code>sudo</code> privileges, you will now need to change the owner to your local user account with <code>chown</code>.</p>
<p><code>bcmryan@desktop:~$ sudo chown --recursive bcmryan:bcmryan /mnt/repi</code></p>
<p>Next, you need to edit your desktop&rsquo;s <code>/etc/fstab</code> to add your information about the mount.
Copy the following text (making sure to edit your username).
The first three space-separated columns define the Samba share location and mount point on your desktop.
The third column defines <code>cifs</code> as the protocol used, and the fourth column defines the options (<a href="https://www.elektronik-kompendium.de/sites/raspberry-pi/2102201.htm">which are more clearly defined in a German-language tutorial</a>): the options <code>noauto,nofail,x-systemd.automount,x-systemd.requires=network-online.target</code> help the system overcome problems with booting if the share is not available on the network at bootup; UID and GID are defined to avoid permissions issues, thus allowing the user to use the share as if it were a local disk; a save location for <code>credentials</code> allows the user to store their password in their <code>/home</code> directory so that not every system user can access is; and clearly defining the character set as <code>iocharset=utf8</code> helps to avoid issues with filenames in with non-<a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> characters.</p>
<pre><code>bcmryan@desktop:~$ sudo tee -a /etc/fstab &lt;&lt; END
//192.168.0.100/storage /mnt/repi cifs noauto,nofail,x-systemd.automount,x-systemd.requires=network-online.target,uid=1000,gid=1000,credentials=/home/bcmryan/.smbcredentials,iocharset=utf8 0 0
END
</code></pre><p>Now it is time to create <code>.smbcredentials</code> in your <code>/home</code> directory as defined in the entry in <code>/etc/fstab</code>.
For this, you input the username and password for the Samba share as defined earlier on the Raspberry Pi server.
(Again make sure to use your local username.)</p>
<pre><code>bcmryan@desktop:~$ tee -a /home/bcmryan/.smbcredentials &lt;&lt; END
username=storagerw
password=passwordsamba
END
</code></pre><p>As storing a password in a plain-text file may allow others access to it using default permissions, use the <a href="https://en.wikipedia.org/wiki/Chmod"><code>chmod</code></a> (change mode) command to give read-write permissions (6) to the file&rsquo;s owner only and no one in their group (0) or not in their group (0).</p>
<p><code>bcmryan@desktop:~$ sudo chmod 600 ./.smbcredentials</code></p>
<p>You can verify this by listing all directories and files in your <code>/home</code> directory and confirming that <code>.smbcredentials</code> is preceded by <code>-rw-------</code> (read-write permissions only for the owner).</p>
<p><code>bcmryan@desktop:~$ ls -lah</code></p>
<p>Back on the Raspberry Pi, it is now time to restart <a href="https://www.samba.org/samba/docs/current/man-html/smbd.8.html"><code>smbd</code></a> (Samba daemon) with <a href="https://manpages.ubuntu.com/manpages/focal/man1/systemctl.1.html"><code>systemctl</code></a> so that the newly configured changes will enacted.
When asked for your password, you will need to enter the password of user pi, which is <code>passwordpi</code>.</p>
<p><code>pi@repi:~$ systemctl restart smbd</code></p>
<p>Now that the changes have been made on the Raspberry Pi, go back to your desktop and remount everything defined in <code>/etc/fstab</code> by completly restarting your machine with <code>reboot</code>.
(Note that <code>sudo mount --all</code> did not allow me to access the Samba share at <code>/mnt/repi</code>, so using the <code>reboot</code> command was required.)</p>
<p><code>bcmryan@desktop:~$ reboot</code></p>
<p>On you log back into your desktop, you are able to access all files on <code>/mnt/repi</code> as if you were on the Raspberry Pi server at <code>/mnt/storage</code>.
You can test this by listing all directories and files available at that mount point.</p>
<p><code>bcmryan@desktop:~$ ls -lah /mnt/repi</code></p>

					</div>

				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">

						</div>
						<h1 class="entry-title">
						  <a href="/repi/containerization-with-docker/" rel="bookmark">Containerization with Docker</a>
						</h1>
					</header>
					<div class="entry-content">
						<p>If you have been following along, you should now be able to access any directory or file via Samba on pretty much any computer or smart device connected through your local network.
That is pretty neat.
If that is enough for you and your needs, you can stop right here, but if you start exploring the world of <a href="https://en.wikipedia.org/wiki/OS-level_virtualization">containerization</a> with <a href="https://en.wikipedia.org/wiki/Docker_(software)">Docker</a>, continue along.</p>
<p>In short, containerization allows you to run a computer system within a larger operating system.
It differs from full <a href="https://en.wikipedia.org/wiki/Virtualization">virtualization</a> in that what is being run is a very bare-bones system and not a full operating system.
You can think about full operating system virtualization as running a full copy of Ubuntu inside of an install of Ubuntu.
You can use your mouse and keyboard within the operating system and even install applications, but once you close the program that is a running the virtual machine, you can no longer access the data or applications saved in it.
Containerization, on the other hand, is more like running a single <a href="https://en.wikipedia.org/wiki/Sandbox_(computer_security)">sandboxed</a> application within an operating system.
It may not be as versitile as running a full operating system, but it does have a few advantages: not only is a containerized application, like an application installed on a virtual machine, only able to access the data, conncted devices, etc. on the host that you allow it to, but it also uses a lot fewer resources than a virtual machine.</p>
<p>Imagine that you want to run an application for online banking.
You could install it on your desktop and use it there.
You may though want to add a layer of security (you would not want a potential virus to gain access to your application data, for instance), so you could install a virtual machine inside of your desktop and only use the virtual machine for that single purpose.
Conversely, you could install a containerized version of the application on your desktop and deny access to data generated by that application to any other application.
Security might be a reason to not install that application directly on your desktop, but the install size and maintainability of the application may be the reason to containerize it and not virtualize it: a modern Windows install can take the better part of a day and dozens of gigabytes in space, while the installation of a Docker image can take as little as a few minutes.
Another added benefit to containzerization over a local installation of an application when security is not as important (as with an install of Jellyfin on a Raspberry Pi server, for example) is that the application data are not scattered all around your system.
If you need to reinstall your base operating system, you can just copy over your configuration and data directory and replace it once you are done.
It is really that easy.
For the reasons of security and portability, containerization was chosen for the Reproducible Pi server build.</p>
<p>For installing Docker, again following <a href="https://blog.linuxserver.io/2017/06/24/the-perfect-media-server-2017/">The Perfect Media Server 2017</a> build guide and <a href="https://www.youtube.com/watch?v=WYI32kx4hPE">accompanying YouTube video</a>, you will use the <a href="https://docs.docker.com/engine/install/ubuntu/#install-using-the-convenience-script">convience install script</a>.
Note that the following command will run a <a href="https://get.docker.com/">script</a> (piped through to the shell) downloaded using <code>curl</code> directly from the internet.
This is generally to be avoided for security reasons, so you should look over it before completing this next step.</p>
<p><code>pi@repi:~$ curl https://get.docker.com | sh</code></p>
<p>Once you are returned to an empty command line, grant user pi access to the newly created group named docker with <code>usermod</code>.</p>
<p><code>pi@repi:~$ sudo usermod --append --groups docker pi</code></p>
<p>You can confirm that user pi is now part of group docker by running the <code>id</code> followed by the username to see the user&rsquo;s group memberships.</p>
<p><code>pi@repi:~$ id pi</code></p>
<p>With <code>sudo</code> privileges (following a post-install reboot, this will no longer be necessary), you can test your Docker install by running (<code>run</code>) the <a href="https://en.wikipedia.org/wiki/%22Hello,_World!%22_program"><code>hello-world</code></a> command.</p>
<p><code>pi@repi:~$ sudo docker run hello-world</code></p>
<p>With this test you can see that Docker was unable to find an included image for <code>hello-world</code> and thus downloaded (pulled) one from its online repository.</p>
<h3 id="docker-compose">Docker Compose</h3>
<p>Now with Docker installed, you are going to install a <a href="https://docs.linuxserver.io/general/docker-compose">Docker Compose image from LinuxServer.io</a>.
Docker Compose is a tool for defining how Docker images should run through a <a href="https://en.wikipedia.org/wiki/YAML">YAML</a> config file.
While setting up and running Docker images is possible without Docker Compose, Docker Compose allows you to save all configuration information for multiple images in a single text file.
This gives you flexibility when migrating your configurations and makes sure that images are run with the same parameters every time (something that is much harder if you need to manually type in your entire command each time you need to restart a service (for instance, after a power outage or following rutine maintence).</p>
<p>To install Docker Compose, you will again need to run a <a href="https://raw.githubusercontent.com/linuxserver/docker-docker-compose/master/run.sh">script</a> downloaded from the internet via <code>curl</code> (with <code>--location</code> and <code>--output</code> defining that the file will be saved and the location where it will be saved), so you should again glance over it before proceeding.
Note that running this command saves the script in <code>/usr/local/bin</code>, so it will now be accessible like any other command line program installed on your server.</p>
<p><code>pi@repi:~$ sudo curl --location https://raw.githubusercontent.com/linuxserver/docker-docker-compose/master/run.sh --output /usr/local/bin/docker-compose</code></p>
<p>In order use Docker Compose, make the file executable (able to be run as a command line program) using the <code>chmod</code> command with option <code>+x</code> and elevated privileges.</p>
<p><code>pi@repi:~$ sudo chmod +x /usr/local/bin/docker-compose</code></p>
<p>To confirm that Docker and Docker Compose have installed correctly, check the version of each program.
First, confirm that docker is running with elevated privileges (again, after a reboot, <code>sudo</code> will no longer be necessary for either program).</p>
<p><code>pi@repi:~$ sudo docker version</code></p>
<p>Now, check the version of Docker Compose.
As this is the first use of Docker Compose, the newest image will be downloaded and installed.</p>
<p><code>pi@repi:~$ sudo docker-compose version</code></p>
<p>In order to update both Docker and Docker Compose, you will just need to download and install the latest version as a script or Docker image, respectively.
For Docker, you simply rerun the script installed earlier (which is again downloaded and then immediately run on the Raspberry Pi).
As Docker has only been installed with this script in the past, you can safely ignore any warnings during installation.</p>
<p><code>pi@repi:~$ curl https://get.docker.com | sh</code></p>
<p>For Docker Compose, on the other hand, you need to first <code>pull</code> the latest image (which is automatically matched to your hardware architecture) and then <a href="https://docs.docker.com/engine/reference/commandline/image_prune/"><code>prune</code></a> any remaining dangling (one neither tagged nor referenced by a container) images, with the option <code>--force</code> meaning that you are not asked for confirmation.</p>
<p><code>pi@repi:~$ sudo docker pull linuxserver/docker-compose:&quot;${DOCKER_COMPOSE_IMAGE_TAG:-latest}&quot; &amp;&amp; sudo docker image prune --force</code></p>
<p>The default location for <code>docker-compose.yml</code> is in the <code>/home</code> directory of the user.
I perfer creating a completely separate directory which houses all Docker-related files in the <code>/</code> (root) directory of the file system.
(Note that this has worked well for me, but it is not a guarentee that going against the default may not cause issues later.)
In order to do this, use the <code>mkdir</code> command with the option <code>--parents</code> to create the directory <code>/docker/docker-compose</code> and its parent <code>/docker</code> with elevated privileges.</p>
<p><code>pi@repi:~$ sudo mkdir --parents /docker/docker-compose</code></p>
<h3 id="jellyfin">Jellyfin</h3>
<p><a href="https://en.wikipedia.org/wiki/Jellyfin">Jellyfin</a> is a media server that allows you to access your media through a browser or native applications on different devices on your local network through a GUI.
To exemplify how Docker Compose can be used on your Raspberry Pi server, you will install Jellyfin and interact with it using your media saved on <code>/mnt/storage</code>.</p>
<p><code>pi@repi:~$ sudo mkdir /docker/jellyfin &amp;&amp; chown --recursive storagero:storage /docker/jellyfin</code></p>
<p>The <a href="https://hub.docker.com/r/linuxserver/jellyfin">Docker Compose example from LinuxServer.io</a> serves as the basis for this install (although I have provided edits and comments applicable to this install).
You will see that Jellyfin is being run by user storagero and thus does not have read-write access to <code>/mnt/storage</code> to avoid potential issues.
This of course though means that metadata will not be able to be exported as <a href="https://en.wikipedia.org/wiki/.nfo">NFO</a> files, so I can not easily move it to another service (such as <a href="https://en.wikipedia.org/wiki/Kodi_(software)">Kodi</a>).
Thus I do not edit any media metadata within Jellyfin and instead have created the correct file system structure and NFO files using <a href="https://www.tinymediamanager.org/">tinyMediaManager</a>.
(There are of course <a href="https://old.reddit.com/r/jellyfin/comments/gdhyzg/to_nfo_or_not_to_nfo/">other opinions</a> regarding the use of NFO files and read-write access for Jellyfin.)
If I need to add or edit data saved on <code>/mnt/storage</code>, I do so over Samba from my desktop and rescan my library from within Jellyfin in order to apply the changes.
Note that the default timezone for this image is Europe/London; change this according to your local timezone.
The line beginning with <code>JELLYFIN_PublishedServerUrl=</code> should be followed by the static IP address of the Raspberry Pi.
Under <code>volumes</code> and <code>devices</code> the path before the colon represents the path on your server, while the path after the colon is how this path is represented within Jellyfin when selecting directory locations.
These are in accordance with the naming scheme I have used for media within <code>/mnt/storage</code>, so you may need to edit these according to your needs.
As this is only instance of Jellyfin will only be used on my local network, I have commented out (thus deactivated) the lines in <code>ports</code> defining <a href="https://en.wikipedia.org/wiki/HTTPS">HTTPS</a> (i.e. encrypted network traffic) and <a href="https://en.wikipedia.org/wiki/User_Datagram_Protocol">UDP</a> (i.e. device discovery) usage, while I have left port 8096 available to access Jellyfin (thus, the address to access Jellyfin will be 192.168.0.100:8096).
Finally, all <code>devices</code> are left activated so that Jellyfin will be able to take advantage of hardware acceleration for transcoding on the Raspberry Pi.
Copy the contents of this file using <code>tee</code> to <code>/docker/docker-compose/docker-compose.yml</code>.</p>
<pre><code>pi@repi:~$ sudo tee -a /docker/docker-compose/docker-compose.yml &lt;&lt; END
version: &quot;2.1&quot;
services:
  jellyfin:
    image: ghcr.io/linuxserver/jellyfin
    container_name: jellyfin
    environment:
      - PUID=201 # user storagero (thus Jellyfin has read-only access to /mnt/storage so as to avoid potential data corruption if there was a problem)
      - PGID=200 # group storage
      - TZ=Europe/London # list of tz abbreviations at https://en.wikipedia.org/wiki/List_of_tz_database_time_zones (change to your correct timezone)
      - JELLYFIN_PublishedServerUrl=192.168.0.100 # optional; based on Raspberry Pi static IP address
    volumes:
      - /docker/jellyfin/config:/config # in created directory
      - /mnt/storage/Movies:/data/movies # based on directory structure
      - /mnt/storage/Series:/data/tvshows # based on directory structure
      - /opt/vc/lib:/opt/vc/lib # optional; for hardware acceleration as well as everything in devices
    ports:
      - 8096:8096 # port to access Jellyfin; thus 192.168.0.100:8096
#      - 8920:8920 # optional
#      - 7359:7359/udp # optional
#      - 1900:1900/udp # optional
    devices:
      - /dev/dri:/dev/dri # optional
      - /dev/vcsm-cma:/dev/vcsm-cma # optional; edited to /dev/vcsm-cma based on https://github.com/michaelmiklis/docker-rpi-monitor/issues/4
      - /dev/vchiq:/dev/vchiq # optional
      - /dev/video10:/dev/video10 # optional
      - /dev/video11:/dev/video11 # optional
      - /dev/video12:/dev/video12 # optional
    restart: unless-stopped
END
</code></pre><p>As these <code>/docker/docker-compose/</code> and <code>/docker/docker-compose/docker-compose.yml</code> were created with <code>sudo</code> privileges, they are owned by <code>root</code>.
Using the <code>chown</code> command with the <code>--recursive</code> option and elevated privileges, give ownership of this directory to user pi and group pi, as this is the user which will be executing the start of Docker Compose.</p>
<p><code>pi@repi:~$ sudo chown --recursive pi:pi /docker/docker-compose</code></p>
<p>Note that a Docker Compose file can hold instructions for running multiple containers.
To do this simply append the parameters to this file, making sure that the name is given so that it lines up with <code>jellyfin:</code> under <code>services:</code>.
Docker Compose was created to be the single config file for all Docker images, thus making your backups much more managable and simplifying your entire server.</p>
<p>You now need to create the directory <code>/docker/jellyfin/config</code> using <code>mkdir --parents</code> with elevated privileges as referenced in <code>/docker/docker-compose/docker-compose.yml</code>.</p>
<p><code>pi@repi:~$ sudo mkdir --parents /docker/jellyfin/config</code></p>
<p>Given that Jellyfin is being run as user storagero and group storage, make this the owner of <code>/docker/jellyfin</code> with <code>chown --recursive</code>.</p>
<p><code>pi@repi:~$ sudo chown --recursive storagero:storage /docker/jellyfin</code></p>
<p>Due to an <a href="https://docs.linuxserver.io/faq#libseccomp">issue with running LinuxServer.io images on operating systems based on 32-bit Debian due to a bug in libseccomp2</a>, you have to enable the backports repository for Debian Buster.</p>
<p><code>pi@repi:~$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 04EE7237B7D453EC 648ACFD622F3D138</code>
<code>pi@repi:~$ echo &quot;deb http://deb.debian.org/debian buster-backports main&quot; | sudo tee --append /etc/apt/sources.list.d/buster-backports.list</code>
<code>pi@repi:~$ sudo apt update --yes</code>
<code>pi@repi:~$ sudo apt install --target-release buster-backports libseccomp2</code></p>
<p>Jellyfin also recommends setting <a href="https://jellyfin.org/docs/general/administration/hardware-acceleration.html#raspberry-pi-3-and-4">graphical processing unit (GPU) memory allocation to 320 MB</a> as described in the Raspberry Pi <a href="https://www.raspberrypi.org/documentation/configuration/config-txt/memory.md">official documentation</a>.</p>
<pre><code>pi@repi:~$ sudo tee /boot/config.txt &lt;&lt; END

# GPU memory allocation for Jellyfin
gpu_mem=320
END
</code></pre><p>Before continuing, you should now <code>update</code>, <code>full-upgrade</code> and <code>reboot</code> your system to make sure that everything to this point has been installed and configured correctly and to avoid potential problems with running Docker without elevated privileges.
Note that a reboot will close your SSH connection.</p>
<p><code>pi@repi:~$ sudo apt update --yes &amp;&amp; sudo apt full-upgrade --yes &amp;&amp; sudo reboot</code></p>
<p>Wait about a minute, and then try to reestablish the SSH connection.
If it fails due to it timing out (i.e. taking too long to connect), wait a few seconds, and try again.</p>
<p><code>bcmryan@desktop:~$ ssh pi@192.168.0.100</code></p>
<p>With your fully up-to-date system, you are now ready to run Jellyfin via Docker Compose.
Due to a <a href="https://github.com/docker/compose/issues/3875#issuecomment-502899871">quirk</a> in the way that Docker Compose works, it must always be started from a relative (and not absolute) path.
Thus, you first need to change into the <code>/docker</code> directory with <a href="https://en.wikipedia.org/wiki/Cd_(command)"><code>cd</code></a> before you can start the Docker container.</p>
<p><code>pi@repi:~$ cd /docker</code></p>
<p>To run Docker Compose with the newly created config file, use the <code>docker-compose</code> command with the option <code>--file</code> for defining the file location and <a href="https://docs.docker.com/engine/reference/commandline/compose_up/"><code>up --detach</code></a> to run the containers in the background.
Running this will download and install the latest Jellyfin image and begin its operation in the background.</p>
<p><code>pi@repi:/docker $ docker-compose --file ./docker-compose/docker-compose.yml up --detach</code></p>
<p>From here, simply enter the IP address followed by the port number (i.e. 192.168.0.100:8096) into any web browser to complete the installation of Jellyfin.
As this is subject to change, I will not document the exact installation steps here, but I will mention the following:
I have enabled an administrator (default name is abc) and separate user accounts, with only the administrator having a password and <a href="https://jellyfin.org/docs/general/server/users/adding-managing-users.html#additional-options">being hidden from the login page</a>.
The path names are those given in the Docker Compose config file (i.e. <code>/mnt/storage/Movies</code> is accessed via <code>/data/movies</code>, and <code>/mnt/storage/Series</code> is accessed via <code>/data/tvshows</code>).
I have left unchecked all data scrappers throughout, as I do not want Jellyfin to edit my data.
Finally, you should be able to enable OpenMax hardware acceleration as described in Jellyfin&rsquo;s <a href="https://jellyfin.org/docs/general/administration/hardware-acceleration.html#enabling-hardware-acceleration">official documentation</a>.</p>
<p>When you finally get around to scanning your media files, note that it can take a very long time (up to a day if you have dozens of television shows with thousands of episodes).
Be patient (and check the administrator dashboard to see how far along you are).</p>
<p>And that is all.
Enjoy your media!</p>

					</div>

				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">

						</div>
						<h1 class="entry-title">
						  <a href="/repi/maintenance/" rel="bookmark">Maintenance</a>
						</h1>
					</header>
					<div class="entry-content">
						<p>Once you have sucessfully set up and started using your new Raspberry Pi server, it is crucial that you keep your system up to date and keep your application data backed up.
Luckily, with the skills you have acquired or reinforced through this tutorial, you should be absolutely fine doing so.
Linux is an incredibly powerful base to the Rasbperry Pi OS explored in this tutorial, and its standard tools work very well for the maintaince of your system.</p>
<h2 id="backups">Backups</h2>
<p>Backing up your data saved on your hard drives (i.e. everything in <code>/mnt/storage</code>) is of course important, and I subscribe to the <a href="https://www.backblaze.com/blog/the-3-2-1-backup-strategy/">3-2-1 backup strategy</a> of having the original file plus one copy locally and another copy in another location to restore any lost data if something catastrophic happens (if your house burns down a local backup will also be lost, but it is less likely that your backup at a family member&rsquo;s house will also be lost).
This section is concerned with backing up application data from Docker itself.
(As there are other scripts, configuration files and helpful explanations throughout this file, it might also not be a bad idea to create a local backup of this document as well for future reference.)
As everything unique to your setup is saved in <code>/docker</code>, this folder should be the main focus of your attention regarding the backing up of application data.</p>
<p>Before beginning with creating a backup, you need to create a folder with <code>mkdir</code> that is separate from your microSD card (if your microSD card were to have a problem, restoring a backup from it would not be possible).
For this folder location, use for instance <code>/mnt/diskMovies1/backup</code>.
This way you know exactly on which physical hard drive the backup is stored (creating <code>/mnt/storage/backup</code> might put it on any hard drive in that array).
Note that you need to use elevated privileges, as <code>/mnt/diskMovies1</code> is owned by user storagerw and group storage.
Note that this directory is owned by user root and group root and thus will require elevated privileges to access.
As backup files should generally not be modified, this seems sensible.</p>
<p><code>pi@repi:~$ sudo mkdir /mnt/diskMovies1/backup</code></p>
<p>For creating the backup, use <code>tar</code> with elevated privileges (as it will be saving a directory not owned by user pi to a folder not owned by user pi); options <code>--create</code> to create a new compressed file, <code>--gzip</code> to specify the compression format, <code>--file</code> to specify the save location of the new file (with the date appended to the file name using the <a href="http://manpages.ubuntu.com/manpages/focal/man1/date.1.html"><code>date</code></a> command following the <a href="https://en.wikipedia.org/wiki/ISO_8601">ISO 8601 standard</a> of year month day) and <code>--verbose</code> to list the files being processed; and finally the directory which is being compressed, i.e. <code>/docker</code>.</p>
<p><code>pi@repi:~$ sudo tar --create --gzip --file /mnt/diskMovies1/backup/docker_$(date +%Y-%m-%d).tar.gz --verbose /docker</code></p>
<p>To restore from the backup, again use the <code>tar</code> command with elevated privileges but this time with options <code>--extract</code>, <code>--gzip</code>, <code>--file</code> (with the location of backup file), <code>--verbose</code> and <code>--directory</code> to specify the extraction location of <code>/</code> (as the directory <code>docker</code> is at the base of the compressed file).</p>
<p><code>pi@repi:~$ sudo tar --extract --gzip --file /mnt/diskMovies1/backup/docker_2021-06-06.tar.gz --verbose --directory /</code></p>
<p>Note that following this restoration of your backup, you will need to adjust permissions of <code>/docker</code>.</p>
<h2 id="updates">Updates</h2>
<p>Updating your system &ndash; along with keeping best practices in mind regarding the use of passwords and keys and the exposure of your system to the open internet &ndash; is a fundamental part of maintaining a secure system.
As any vulnerability in your system can be a gateway into your local network &ndash; and thus all other computers and smart devices in your home &ndash; it is absolutely imperative to run updates often in order to patch any security holes that may exist.</p>
<h3 id="apt">apt</h3>
<p>Using <code>apt</code>, downloading updates and installing upgrades is as simple as <code>sudo apt update --yes &amp;&amp; sudo apt full-upgrade --yes</code>.
This simple command will make sure that your computing experience remains safe and secure and almost never introduces insability in your system (although this is something that you will always need to keep an eye on).</p>
<h3 id="custom-scripts">Custom scripts</h3>
<p>As both Docker and Docker Compose were installed by executing a script downloaded from the internet and as Docker pulls new images from repositories defined in Docker Compose, updates to these will need to be run through a system separate from <code>apt</code>.
To keep these systems up to date, I have written a simple script that you should periodically run.
To save this script, again use <code>tee</code>.
You will notice that the file <code>dockerupdate</code> is being saved with elevated privileges to the directory <code>/usr/local/bin/</code>.
As this directory in your <a href="https://en.wikipedia.org/wiki/PATH_(variable)">PATH</a> (i.e. a list of directories with programs that can be executed without further specification), you will only need to enter <code>dockerupate</code> in your terminal emulator to run it.
The script functions as follows.
The script beging with a <a href="https://en.wikipedia.org/wiki/Shebang_(Unix)"><code>shebang</code></a> (#!) and <code>/bin/bash</code> to define it as a Bash script.
You are first prompted that you will be updating Docker, Docker Compose and Docker images.
As this will immediately close these programs, you should not use this script while they are in use.
The script gives you 30 seconds to end the script (by entering Ctrl+C) via the <a href="http://manpages.ubuntu.com/manpages/focal/man3/sleep.3.html"><code>sleep</code></a> command.
The <code>sleep</code> command is repeated throughout the script to make sure that each process has fully finished before beginning the next one.
The <a href="http://manpages.ubuntu.com/manpages/focal/man1/tar.1.html"><code>tar</code></a> command creates a simple backup in a compressed file for restoring everything in <code>/docker</code> if needed later.
As Docker Compose can only be run via relative path, the script changes you to a parent directory, i.e. <code>/docker</code>.
Docker then stops all containers with <a href="https://docs.docker.com/engine/reference/commandline/container_stop/"><code>docker container stop</code></a> by listing them with <code>$(docker container ls --all --quiet)</code> and executing the stop command to all listed (i.e. all containers; <code>--quiet</code> lists only the container ID so that every stays understandable).
The newest <a href="https://docs.linuxserver.io/general/docker-compose">Docker Compose image from LinuxServer.io</a> is again pulled, and all dangling images are pruned.
Docker Compose then pulls all images defined in Docker Compose config file and starts them in the background.
Finally, you are returned to your former working directory (since this was changed to <code>/docker</code> at the beginning of the script).
You will notice that before everything dollar sign (<code>$</code>) there is a backslash (<code>\</code>); this is Bash&rsquo;s <a href="https://www.gnu.org/software/bash/manual/html_node/Escape-Character.html">escape character</a> and is used so that what literally follows is displayed (and thus while saving the script, the variables themselves are not used).</p>
<pre><code>pi@repi:~$ sudo tee /usr/local/bin/dockerupdate &lt;&lt; END
#! /bin/bash

echo &quot;This script will stop all Docker containers and update Docker, Docker Compose
and all Docker images. Cease the use of any Docker containers immediately. If you
would like to stop this script, you have 30 seconds to do so by entering Ctrl+C.&quot;

# sleep for 30 seconds
sleep 30s

# back up /docker
sudo tar --create --gzip --file /mnt/diskMovies1/backup/docker_$(date +%Y-%m-%d).tar.gz --verbose /docker

# change directory because an update to Docker Compose can only be run via a relative path (https://github.com/docker/compose/issues/3875#issuecomment-502899871)
cd /docker

# stop all Docker containers
docker container stop \$(docker container ls --all --quiet)

# sleep for 5 seconds
sleep 5s

# update Docker
curl https://get.docker.com | sh

# sleep for 5 seconds
sleep 5s

# update Docker Compose
docker pull linuxserver/docker-compose:&quot;\${DOCKER_COMPOSE_IMAGE_TAG:-latest}&quot;
docker image prune --force

# sleep for 5 seconds
sleep 5s

# update all images with Docker Compose
docker-compose --file ./docker-compose/docker-compose.yml pull

# sleep for 5 seconds
sleep 5s

# start all containers in background
docker-compose --file ./docker-compose/docker-compose.yml up --detach

# return to former working directory
cd &quot;\$OLDPWD&quot;
END
</code></pre><p>So that the script can be executed, change the mode to executable using <code>chmod +x</code>.</p>
<p><code>pi@repi:~$ sudo chmod +x /usr/local/bin/dockerupdate</code></p>
<p>Test this script with the newly created <code>dockerupdate</code> command.</p>
<p><code>pi@repi:~$ dockerupdate</code></p>
<p>To schedule automatic updates, you can employ <a href="https://en.wikipedia.org/wiki/Cron">cron</a>, a time-based scheduler for running commands.
Using the correct formatting for cron, the job <code>* 4 * * 1 /usr/local/bin/dockerupdate &gt;/dev/null 2&gt;&amp;1</code> is defined as the 04:00 (i.e. 4:00 AM) Monday execution of command <code>/usr/local/bin/dockerupdate</code> without logs (by sending all output to <code>/dev/null</code>).
While this is possible to input using <code>crontab -e</code>, I perfer to directly <a href="https://stackoverflow.com/questions/4880290/how-do-i-create-a-crontab-through-a-script">create a cron job with a single command</a>, thus making it easier for scripting.</p>
<p><code>pi@repi:~$ (crontab -l 2&gt;/dev/null; echo &quot;* 4 * * 1 /usr/local/bin/dockerupdate &gt;/dev/null 2&gt;&amp;1&quot;) | crontab -</code></p>
<h2 id="nuking-and-paving">Nuking and paving</h2>
<p>After fully configuring your system, I highly recommend following the <a href="https://www.raspberrypi.org/documentation/linux/filesystem/backup.md">official documentation</a> and creating a backup image of your microSD card (with your drive letter changed and after unmounting your microSD card from your desktop along with your backup location).</p>
<p><code>bcmryan@desktop:~$ sudo dd bs=4M if=/dev/sdd of=/path/to/backups/PiOS_$(date +%Y-%m-%d).img</code></p>
<p>Running this command in reverse flashes your microSD card.
(Again paying attention to the drive letter.)</p>
<p><code>bcmryan@desktop:~$ sudo dd bs=4M if=/path/to/backups/PiOS_2021-06-06.img of=/dev/sdd</code></p>
<p>That said, given the flexibility and relative ease of setting up a Raspberry Pi server, I genuinely think that the path of least resistence following a catastrophic failure in many cases is to simply rebuild your server and populate your Docker application data from the last local backup.
This rather drastic approach is called <a href="https://en.wiktionary.org/wiki/nuke_and_pave">nuking and paving</a>.
This approach allows you to reevaluate exactly what you are installing and why and may avoid problems if there were to have been bugs in earlier versions of software that was actually saved in the backup of the microSD card.
Since the applications themselves are not being backed up using the above method for Docker (i.e. creating a backup of <code>/docker</code>), this is generally not an issue with the application data of containers.</p>

					</div>

				</article>
        
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">

						</div>
						<h1 class="entry-title">
						  <a href="/repi/conclusion/" rel="bookmark">Conclusion</a>
						</h1>
					</header>
					<div class="entry-content">
						<p>So there you have it.
Welcome to your fully functional file and media server.</p>
<p>Let us review what you did in this tutorial.
First, you downloaded Raspberry Pi OS and flashed it to a microSD card.
From your desktop, you then set up SSH and gave yourself permanent access to the terminal emulator of the Raspberry Pi with an SSH key.
Additionally, you set static IP addresses on both your desktop and Raspberry Pi so that you do have to fumble around with dynamically allocated addresses.
For this same reason, you also set the Raspberry Pi&rsquo;s hostname.
Next, in order to control access to your files, you created different users with different permissions.
With mergerfs, you then merged externally attached hard drives into a single directory.
This single directory was then shared across the network via Samba, with all devices on the local network given read-only access and a single device given read-write access.
Using Docker and Docker Compose a containerized version of the Jellyfin media server was created with read-only access to the merged directory so as to prevent data loss.
Using <code>apt</code>, <code>cron</code> and custom scripts, you can now keep your system up to date and your backups secured.</p>
<p>Wow, that is a pretty impressive system, and it is just as amazing that it was built with readily available hardware and <a href="https://en.wikipedia.org/wiki/Free_and_open-source_software">free and open-source</a> software.
Remebering that this project was about creating a modular and reproducible server, I have a challenge for you: break it.
You read that correctly.
Rip out a hard drive; delete a couple packages; try to destroy your Jellyfin Docker container, or just delete your entire Docker Compose config file.
The point of this project is not only to create a file and media server but also to help you understand that modularity and reproducibility are your friends.
You should not be afraid of your system, and you should not be left out in the dark when you inevitably need to restore from a backup or need to just completely wipe a machine.
So, build your machine (and your network) with the knowledge that when (not if) the worst happens, you are prepared.</p>
<p>Personally, I am not finished with this project.
My next step is create a script that you can run directly from your desktop that will allow you to define your SSH key, static IP address, hostname, etc. before you even power on your Raspberry Pi for the first time.
A following script should then install all necessary packages, set up user accounts, etc. directly when executed directly from your Raspberry Pi.
My hope is that the knowledge you have gained from completing a build command by command will empower you to be able to use these scripts to restore your Raspberry Pi server following a catostrophic (or even not-so-catostrophic such as a major version upgrade) failure.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>Along with the great <a href="https://www.raspberrypi.org/documentation/">official documentation</a> from the Raspberry Pi Foundation and the links cited throughout, this project has been greatly influenced by <a href="https://perfectmediaserver.com/">The Perfect Media Server</a> project as well as general knowledge picked up over the years on the <a href="https://www.reddit.com/r/DataHoarder/">r/DataHoarder</a> subreddit and in technical forum posts in general.
Learning to read documentation and honing your Google skills really will help you in your technical journey.
I wish you all the best of luck.</p>
<h2 id="faqs">FAQs</h2>
<p>I hope that this guide was thorough enough, but if you still have any other questions, take a look at this list of frequently asked questions below!</p>
<h3 id="what-can-i-do-if-i-do-not-have-access-to-a-linux-desktop">What can I do if I do not have access to a Linux desktop?</h3>
<p>The commands that are given throughout this guide are based on Linux. While I am nearly certain that they should also work on macOS via the Terminal app, I have not tested them.
On Windows, you can try Windows Subsystem for Linux and/or PowerShell, but I cannot guarentee compatibility.
I strongly urge you to <a href="https://ubuntu.com/tutorials/create-a-usb-stick-on-windows">create a Linux live USB stick</a> so you can follow along as intended.</p>
<h3 id="how-can-i-get-even-bleeding-edge-firmware-and-kernel-updates">How can I get even bleeding-edge firmware and kernel updates?</h3>
<p>We can update the Raspberry Pi&rsquo;s firmware with <a href="https://github.com/Hexxeh/rpi-update"><code>rpi-update</code></a>.
(Note that upgrading the firmware is not without risk.
Although <a href="https://jellyfin.org/docs/general/administration/hardware-acceleration.html#raspberry-pi-3-and-4">the Jellyfin project does consider this important for hardware acceleration</a>, it is not absolutely necessary.
Nevertheless, it will allow you to have the newest kernel and firmware updates available.
Proceed with caution.)</p>
<p><code>pi@raspberrypi:~$ sudo apt install --yes rpi-update &amp;&amp; sudo rpi-update</code></p>
<p>You will be asked to confirm that you are comfortable with this upgrade.
If you are, enter <code>y</code>.
The firmware and kernel updates will now be applied.
You system is now on the absolute bleeding edge.</p>
<h3 id="i-keep-trying-to-reach-raspberrypilocal-but-it-just-will-not-resolve">I keep trying to reach raspberrypi.local, but it just will not resolve.</h3>
<p>So from my desktop, I will ping every currently used IP address on my local network to see what is in use with the program <a href="https://en.wikipedia.org/wiki/Nmap"><code>Nmap</code></a>, which I first need to install.</p>
<p><code>bcmryan@desktop:~$ sudo apt install --yes nmap</code></p>
<p>From there, I will have <code>Nmap</code> check which IP addresses are being used in my subnet.
I know from its inital setup that my router can be accessed at <code>192.168.0.1</code>, so since my Raspberry Pi and desktop are directly connected to my router, I know that both devices should have an IP address between <code>192.168.0.0</code> and <code>192.168.0.255</code> (a total of 256 addresses, which is definitely enough all the devices on my network).
The command used for this is pretty easy: <code>-sn</code> performs a ping scan, which means that the program is just seeing if the IP is in use (akin to ringing anyone&rsquo;s doorbell in an apartment building and seeing responds); <code>192.168.0.0-255</code> simply defines the range of all IP addresses to be scanned.</p>
<p><code>bcmryan@desktop:~$ nmap -sn 192.168.0.0-255</code></p>
<p>My result says that all addresses between 192.168.0.1 (my router) and 192.168.0.8 are in use (which are dynamic IP addresses, given on a first-come-first-served basis to whatever desktop, smartphone, tablet, smart device, etc. signed onto the network first), along with 192.168.0.20 and 192.168.0.25 (which are static IP addresses, something to which I will come shortly).</p>
<p>Since I do not know which IP address is used by the Raspberry Pi, I am just going to try to log in to each address via SSH with the default username and password until I find it.</p>
<p><code>bcmryan@desktop:~$ ssh pi@192.168.0.2</code></p>
<p>And it did not work.
That is not a problem.
Because just repeating the command (click the up arrow on your keyboard to get the most recent command) with a different last number on the IP address, I was able to find that the Raspberry Pi has the IP address 192.168.0.5.</p>
<h3 id="i-am-happy-with-just-using-samba-is-installing-jellyfin-absolutely-necessary">I am happy with just using Samba. Is installing Jellyfin absolutely necessary?</h3>
<p>This is your system.
You can do with it whatever you please.
I personally used a simple Samba share for at least a year before I saw the need to install Jellyfin.
Adding the nice GUI of Jellyfin increased the <a href="https://en.wikipedia.org/wiki/Wife_acceptance_factor">appeal to my family members</a> who did not have the same urge to browse through directories to find backups of discs that we physically own (often causing them to just use the physical DVD or Blu-Ray instead of connecting to Samba at all) that I did.
Also the ability to create users and track what has been watched has been an absolute godsend.</p>
<p>But, I am also the first to admit that Jellyfin is not perfect.
ISO (i.e. an image of a full disc instead of ripped individual titles) playback is lacking to say the least (which is particularly interesting considering that Kodi and VLC, two other open-source projects, both play back the same files with no problems), and I honestly do not know if a file is transcoding correctly or not (or, for instance, if an uncompressed rip of a UHD Blu-Ray might just be too much to transcode on a Raspberry Pi 4 with 4 GB of RAM).
But to me, the pros outweigh the cons.
And since my media is available to me on my Samba share anyway, I can always just play any ISO file directly in VLC, and through the <a href="https://jellyfin.org/docs/general/clients/kodi.html#jellyfin-for-kodi">Kodi plugin</a>, I could also just it using that interface.
That is truly the power of open-source software.
It may not be perfect, but there are usually ways to make it do what you want if you put a bit of time into managing it.</p>
<p>For this tutorial, Jellyfin served two purposes: I wanted to exemplify how easy it is to set up a container with Docker Compose, and I personally wanted to document installing Jellyfin with hardware acceleration for future use.
If Jellyfin does not suit your needs, that is perfectly fine.
There are many <a href="https://perfectmediaserver.com/day-two/top10apps/">other great self-hosted applications for you to try</a>.</p>
<h3 id="is-there-a-graphical-way-to-set-system-settings">Is there a graphical way to set system settings?</h3>
<p>For changing settings like the hostname as in this example, you can use the powerful tool <code>raspi-config</code>.
As the program is pretty powerful, it requires <code>sudo</code> privileges.</p>
<p><code>pi@raspberrypi:~$ sudo raspi-config</code></p>
<p>From here, make sure that the line <code>1 System Options</code> is highlighted, and hit enter.
Now hit the down arrow until <code>S4 Hostname</code> is highlighted, and again hit enter.
You will now be given a warning about valid characters in a hostname.
Make sure that yours complies.
Enter a valid hostname like <code>repi</code>.
Hit enter.
Type in your new hostname, and push the down arrow key so that <code>&lt;Ok&gt;</code> is highlighted, and hit enter.</p>
<p>Great.
The new hostname should now be set.
From here, you can choose to look at some other settings (such as locale and timezone in <code>5 Localisation Options</code>).
Here again, <a href="https://www.raspberrypi.org/documentation/configuration/raspi-config.md">the official documentation</a> is very extensive.
Once you are finished, select <code>&lt;Finish&gt;</code> with the right arrow key, and hit enter to exit.</p>
<h3 id="i-chose-the-exfat-file-system-so-that-my-drive-could-be-easily-read-by-windows-macos-and-linux-but-i-am-having-trouble-getting-it-to-properly-work">I chose the exFAT file system so that my drive could be easily read by Windows, macOS and Linux, but I am having trouble getting it to properly work.</h3>
<p>While the choice of exFAT as a file system makes sense for an external hard drive that is used with multiple operating systems, if the drive is being used in a file server with Samba, there will be no problem reading or writing to a file system like ext4, which has the benefit of <a href="https://en.wikipedia.org/wiki/Journaling_file_system">journaling</a>.
That said, if you would still like to use exFAT (as I did for many months before transitioning my files over the ext4), you will need to install <code>exfat-fuse</code> and <code>exfat-utils</code> (<code>sudo apt install --yes exfat-fuse exfat-utils</code>) and add an entry to <code>/etc/fstab</code> such as <code>UUID=1234-5678 /mnt/diskMovies1 exfat-fuse defaults,uid=200,gid=200 0 0</code>.
Note that UID and GID are defined here, as I personally have had issues with permissions with exFAT (an alternative would also be 1000 and 1000 for the current user and current group if problems still persist).</p>

					</div>

				</article>
        
			</div>
		</div>

		<center class="">
			<ul class="pagination">
        


			</ul>
		</center>
	</div>	

</main>

    
    
      <footer id="footer">
	<div class="container">
		<div class="row">
			

			
			<div class="col-md-3 widget">
				<h3 class="widget-title">Contact me</h3>
				<div class="widget-body">
					<p class="follow-me-icons">
            
							
								<a href="https://twitter.com/bcmryan" target="_blank"><i class="fab fa-twitter-square fa-1x"></i></a>
							
            
							
								<a href="https://www.linkedin.com/in/bcmryan" target="_blank"><i class="fab fa-linkedin fa-1x"></i></a>
							
            
							
								<a href="https://github.com/bcmryan" target="_blank"><i class="fab fa-github fa-1x"></i></a>
							
            
							
								<a href="mailto:bcm.ryan@gmail.com" target="_blank"><i class="fas fa-envelope-square fa-1x"></i></a>
							
            
					</p>
				</div>
			</div>
			

			

			

		</div> 
	</div>
</footer>

<footer id="underfooter">
	<div class="container">
		<div class="row">

			<div class="col-md-6 widget">
				<div class="widget-body">
					<p></p>
				</div>
			</div>

			<div class="col-md-6 widget">
				<div class="widget-body">
					<p class="text-right">
						
						Copyright &copy; Brendan Ryan<br>
						Designed as <a href="http://www.gettemplate.com" rel="designer">Initio by GetTemplate</a> - Powered by <a href="https://gohugo.io/" rel="poweredby">Hugo</a> <br>
						Built on <a href="https://github.com/bcmryan/bcmryan.github.io_source">GitHub</a> - Hosted on <a href="https://github.com/bcmryan/bcmryan.github.io">GitHub</a>
					</p>
				</div>
			</div>

		</div> 
	</div>
</footer>




<script src="https://code.jquery.com/jquery-1.12.4.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>




<script src="/js/bundle.min.f4a965ad0a8118e32f8f0f158ff3aadbacf700934c22286a1a5b245105e9006da73a873b001a160db22498909c1df14d1f835dba5ad76f80b32b0234182b2a58.js" integrity="sha512-9KllrQqBGOMvjw8Vj/Oq26z3AJNMIihqGlskUQXpAG2nOoc7ABoWDbIkmJCcHfFNH4NdulrXb4CzKwI0GCsqWA=="></script>

</body>
</html>

    


      

  </body>
  
</html>
